import os
import time
from urllib.error import URLError


def download_standard_datasets(base_root: str, dataset_list) -> None:
    """
    æ ¹æ® dataset_list ä¸‹è½½æ•°æ®é›†åˆ° base_rootï¼š
    - caltech101 (Caltech-101)
    - oxford_pets (Oxford-IIIT Pet)
    - oxford_flowers (Oxford Flowers 102)
    - food101 (Food-101)

    å‚æ•°:
        base_root: æ•°æ®é›†ä¿å­˜çš„æ ¹ç›®å½•
        dataset_list: è¦ä¸‹è½½çš„æ•°æ®é›†åˆ—è¡¨ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²ï¼ˆå•ä¸ªæ•°æ®é›†ï¼‰æˆ–åˆ—è¡¨ï¼ˆå¤šä¸ªæ•°æ®é›†ï¼‰
    
    ä¾èµ– torchvisionã€‚
    """
    os.makedirs(base_root, exist_ok=True)
    try:
        from torchvision import datasets as tvd
    except Exception as e:
        print("æœªå®‰è£… torchvisionï¼Œè¯·å…ˆæ‰§è¡Œ: pip install torchvision")
        raise e

    # æ ‡å‡†åŒ– dataset_list ä¸ºåˆ—è¡¨æ ¼å¼
    if isinstance(dataset_list, str):
        dataset_list = [dataset_list]
    elif dataset_list is None:
        # å¦‚æœæœªæŒ‡å®šï¼Œä¸‹è½½æ‰€æœ‰é»˜è®¤æ•°æ®é›†
        dataset_list = ['caltech101', 'oxford_pets', 'oxford_flowers', 'food101']

    print(f"ä¸‹è½½ç›®æ ‡ç›®å½•: {base_root}")
    print(f"å°†ä¸‹è½½æ•°æ®é›†: {', '.join(dataset_list)}")

    # æ•°æ®é›†åç§°åˆ°ä¸‹è½½å‡½æ•°çš„æ˜ å°„
    dataset_downloaders = {
        'caltech-101': ('Caltech101', tvd.Caltech101),
        'oxford_pets': ('Oxford-IIIT Pet', tvd.OxfordIIITPet),
        'oxford_flowers': ('Flowers102', tvd.Flowers102),
        'food-101': ('Food-101', tvd.Food101),
    }

    # æ ¹æ® dataset_list ä¸‹è½½æŒ‡å®šçš„æ•°æ®é›†
    for dataset_key in dataset_list:
        dataset_key_normalized = dataset_key.lower().strip()
        if dataset_key_normalized in dataset_downloaders:
            name, downloader = dataset_downloaders[dataset_key_normalized]
            # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»ºå•ç‹¬çš„å­ç›®å½•ï¼šbase_root/dataset
            dataset_dir = os.path.join(base_root, dataset_key_normalized)
            os.makedirs(dataset_dir, exist_ok=True)
            
            # æ·»åŠ é‡è¯•æœºåˆ¶å¤„ç†SSLé”™è¯¯
            max_retries = 3
            retry_delay = 5  # ç§’
            success = False
            
            for attempt in range(1, max_retries + 1):
                try:
                    if attempt > 1:
                        print(f"ç¬¬ {attempt} æ¬¡å°è¯•ä¸‹è½½ {name} ...")
                    else:
                        print(f"ä¸‹è½½ {name} åˆ° {dataset_dir} ...")
                    downloader(root=dataset_dir, download=True)
                    print(f"{name} ä¸‹è½½å®Œæˆ")
                    success = True
                    break
                except (URLError, Exception) as e:
                    error_msg = str(e)
                    if "SSL" in error_msg or "EOF" in error_msg:
                        if attempt < max_retries:
                            print(f"âš ï¸  SSL/ç½‘ç»œé”™è¯¯: {error_msg}")
                            print(f"ç­‰å¾… {retry_delay} ç§’åé‡è¯• ({attempt}/{max_retries})...")
                            time.sleep(retry_delay)
                            retry_delay *= 2  # æŒ‡æ•°é€€é¿
                        else:
                            print(f"âŒ {name} ä¸‹è½½å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰: {error_msg}")
                            print(f"   æç¤ºï¼šè¿™é€šå¸¸æ˜¯ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œå¯ä»¥ç¨åæ‰‹åŠ¨é‡è¯•")
                    else:
                        print(f"âŒ {name} ä¸‹è½½å¤±è´¥: {error_msg}")
                        break
            
            if not success:
                print(f"ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åæ‰‹åŠ¨ä¸‹è½½ {name}")
        else:
            print(f"âš ï¸  æœªçŸ¥æ•°æ®é›†: {dataset_key}ï¼Œè·³è¿‡")


