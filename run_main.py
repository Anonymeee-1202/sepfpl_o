import os
import re
import shlex
from pathlib import Path
from collections import defaultdict
from datasets import download_standard_datasets

# ==================== é€šç”¨é…ç½® ====================
# ç»Ÿä¸€çš„æ•°æ®é›†æ ¹ç›®å½•ã€‚æ‰€æœ‰ä¸‹è½½å’Œè®­ç»ƒéƒ½é»˜è®¤ä½¿ç”¨è¯¥ç›®å½•ã€‚
root = os.path.expanduser('~/dataset')


# ==================== å®éªŒé…ç½® ====================
# æœ¬æ–‡ä»¶ä¸­é¢„å®šä¹‰äº†å››ç±»å®éªŒé…ç½®ï¼š
#  - EXPERIMENT_1_SIMPLE_CONFIGï¼šä¸»å®éªŒï¼ˆSimple è®¾ç½®ï¼‰ï¼Œæ ‡å‡†æ•°æ®é›† + 10 ä¸ªå®¢æˆ·ç«¯ï¼›
#  - EXPERIMENT_1_HARD_CONFIGï¼šä¸»å®éªŒï¼ˆHard è®¾ç½®ï¼‰ï¼ŒCIFAR-100 + ä¸åŒå®¢æˆ·ç«¯æ•°é‡ï¼›
#  - EXPERIMENT_2_RANK_CONFIGï¼šæ¶ˆèå®éªŒ 2.1ï¼Œè€ƒå¯Ÿä¸åŒ rank å¯¹ SepFPL çš„å½±å“ï¼›
#  - EXPERIMENT_2_ABLATION_CONFIGï¼šæ¶ˆèå®éªŒ 2.2â€“2.4ï¼Œè€ƒå¯Ÿ HCSE ä¸æ—¶é—´è‡ªé€‚åº”éšç§åˆ†é…æœºåˆ¶ã€‚

# å®éªŒ1.1ï¼šä¸»å®éªŒ - Simple è®¾ç½®
# ç›®æ ‡ï¼šåœ¨æ ‡å‡†æ•°æ®é›†ä¸Šè¯„ä¼°ä¸åŒçŸ©é˜µåˆ†è§£æ–¹æ³•çš„ä¸ªæ€§åŒ–èƒ½åŠ›ä¸æ³›åŒ–èƒ½åŠ›ï¼ˆå®¢æˆ·ç«¯æ•°å›ºå®šä¸º 10ï¼‰
EXPERIMENT_1_SIMPLE_CONFIG = {
    'exp_name': 'exp1',  # wandb group åç§°
    'seed_list': [1],    # éšæœºç§å­åˆ—è¡¨ï¼ˆå¯æ‰©å±•ä¸ºå¤šä¸ªä»¥åšé‡å¤å®éªŒï¼‰
    'dataset_list': ['caltech-101', 'oxford_pets', 'oxford_flowers', 'food-101'],
    'factorization_list': ['promptfl', 'fedotp', 'fedpgp', 'dpfpl', 'sepfpl'],
    # å™ªå£°çº§åˆ«åˆ—è¡¨ï¼š0.0 è¡¨ç¤ºæ— å·®åˆ†éšç§ï¼Œå…¶ä»–ä¸ºé«˜æ–¯å™ªå£°æ ‡å‡†å·®
    'noise_list': [0.0, 0.4, 0.2, 0.1, 0.05, 0.01],
    'rank': 8,        # ä½ç§©çŸ©é˜µåˆ†è§£çš„é»˜è®¤ç§©
    'num_users': 10,  # å®¢æˆ·ç«¯æ•°é‡ï¼ˆSimple ä¸­å›ºå®šä¸º 10ï¼‰
    'round': 30,      # é€šä¿¡è½®æ•°
}

# å®éªŒ1.2ï¼šä¸»å®éªŒ - Hard è®¾ç½®
# ç›®æ ‡ï¼šåœ¨ CIFAR-100 ä¸Šï¼Œè€ƒå¯Ÿä¸åŒå®¢æˆ·ç«¯æ•°é‡å¯¹è®­ç»ƒè¡¨ç°ä¸ä¸ªæ€§åŒ–æ•ˆæœçš„å½±å“
EXPERIMENT_1_HARD_CONFIG = {
    'exp_name': 'exp1',
    'seed_list': [1],
    'dataset_list': ['cifar-100'],
    'factorization_list': ['promptfl', 'fedotp', 'fedpgp', 'dpfpl', 'sepfpl'],
    'noise_list': [0.0, 0.4, 0.2, 0.1, 0.05, 0.01],
    'rank': 8,
    # ä¸åŒå®¢æˆ·ç«¯æ•°é‡è®¾ç½®ï¼Œç”¨äºè€ƒå¯Ÿç³»ç»Ÿåœ¨è§„æ¨¡å˜åŒ–æ—¶çš„å¯æ‰©å±•æ€§
    'num_users_list': [25, 50],
    'round': 30,
}

# å®éªŒ2.1ï¼šæ¶ˆèå®éªŒ - Rank å½±å“
# ç›®æ ‡ï¼šä»…åœ¨ SepFPL ä¸Šï¼Œåˆ†æä¸åŒ rank å¯¹è¡¨ç¤ºèƒ½åŠ›ã€æ”¶æ•›é€Ÿåº¦åŠæ€§èƒ½çš„å½±å“
EXPERIMENT_2_RANK_CONFIG = {
    'exp_name': 'exp2',
    'seed_list': [1],
    # åªé€‰å–éƒ¨åˆ†æ•°æ®é›†ï¼ŒåŠ å¿«æ¶ˆèå®éªŒé€Ÿåº¦
    'dataset_list': ['caltech-101', 'oxford_pets'],
    'factorization_list': ['sepfpl'],
    # ç²¾ç®€çš„å™ªå£°çº§åˆ«ç»„åˆï¼ˆä¸­/ä½/æä½éšç§å™ªå£°ï¼‰ï¼Œç”¨äºè§‚å¯Ÿè¶‹åŠ¿
    'noise_list': [0.4, 0.1, 0.01],
    'rank_list': [4, 8, 16],  # ä¸åŒ rank è®¾ç½®
    'num_users': 10,
    'round': 30,
}

# å®éªŒ2.2â€“2.4ï¼šæ¶ˆèå®éªŒ - HCSE ä¸æ—¶é—´è‡ªé€‚åº”éšç§æœºåˆ¶
# ç›®æ ‡ï¼šåˆ†ç¦»è€ƒå¯Ÿ HCSE ä¸æ—¶é—´è‡ªé€‚åº”éšç§åˆ†é…æœºåˆ¶å„è‡ªçš„è´¡çŒ®ã€‚
# factorization å˜ä½“è¯´æ˜ï¼š
#   - sepfpl               : å®Œæ•´æ¨¡å‹ï¼ˆHCSE + æ—¶é—´è‡ªé€‚åº”éšç§åˆ†é…ï¼‰ï¼›
#   - dpfpl                : åŸºçº¿ç‰ˆæœ¬ï¼ˆæ—  HCSEã€æ— æ—¶é—´è‡ªé€‚åº”ï¼Œä»… DPï¼‰ï¼›
#   - sepfpl_hcse          : ä»…å¯ç”¨ HCSEï¼Œä¸ä½¿ç”¨æ—¶é—´è‡ªé€‚åº”éšç§åˆ†é…ï¼›
#   - sepfpl_time_adaptive : ä»…å¯ç”¨æ—¶é—´è‡ªé€‚åº”éšç§åˆ†é…ï¼Œä¸ä½¿ç”¨ HCSEã€‚
EXPERIMENT_2_ABLATION_CONFIG = {
    'exp_name': 'exp2',
    'seed_list': [1],
    'dataset_list': ['caltech-101', 'oxford_pets'],
    'factorization_list': ['sepfpl', 'dpfpl', 'sepfpl_hcse', 'sepfpl_time_adaptive'],
    # åŒ…å«æ— å™ªå£°ï¼ˆ0.0ï¼‰å’Œä¸€ä¸ªå…¸å‹ DP å™ªå£°çº§åˆ«ï¼ˆ0.1ï¼‰ï¼Œä¾¿äºå¯¹æ¯”
    'noise_list': [0.0, 0.1],
    'rank': 8,
    'num_users': 10,
    'round': 30,
}

# é»˜è®¤å®éªŒé…ç½®ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
# è‹¥ run_experiment æœªæ˜¾å¼ä¼ å…¥ configï¼Œåˆ™ä½¿ç”¨è¯¥é…ç½®
EXPERIMENT_CONFIG = EXPERIMENT_1_SIMPLE_CONFIG


# ==================== æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ====================
def run(root, dataset, users, factorization, rank, noise, seed, round=10, gpus=None, exp_name=None, task_id=None):
    """
    è¿è¡Œå•ä¸ªå®éªŒä»»åŠ¡ï¼ˆå®é™…è°ƒç”¨ srun_main.shï¼‰

    Args:
        root (str): æ•°æ®é›†æ ¹ç›®å½•ã€‚
        dataset (str): æ•°æ®é›†åç§°ï¼Œä¾‹å¦‚ 'caltech-101'ã€‚
        users (int): å®¢æˆ·ç«¯æ•°é‡ã€‚
        factorization (str): ä½¿ç”¨çš„çŸ©é˜µåˆ†è§£æ–¹æ³•åç§°ã€‚
        rank (int): ä½ç§©çŸ©é˜µåˆ†è§£çš„ç§©ã€‚
        noise (float): å·®åˆ†éšç§å™ªå£°çº§åˆ«ï¼ˆé«˜æ–¯å™ªå£°æ ‡å‡†å·®ï¼‰ã€‚
        seed (int): éšæœºç§å­ã€‚
        round (int): é€šä¿¡è½®æ•°ã€‚
        gpus (str | None): æŒ‡å®šå¯è§ GPUï¼Œå¦‚ '0' æˆ– '0,1'ã€‚è‹¥ä¸º None åˆ™ä¸æ˜¾å¼è®¾ç½®ã€‚
        exp_name (str | None): å®éªŒåï¼Œç”¨ä½œ wandb groupã€‚
        task_id (str | None): ä»»åŠ¡ IDï¼Œç”¨äºæ—¥å¿—æ ‡è¯†ã€‚
    """
    dataset_yaml = f'configs/datasets/{dataset}.yaml'
    prefix = f"CUDA_VISIBLE_DEVICES={gpus} " if gpus else ""
    wandb_group = shlex.quote(str(exp_name)) if exp_name else ""
    task_id_value = shlex.quote(str(task_id)) if task_id else '""'
    os.system(
        f'{prefix}bash srun_main.sh '
        f'{root} {dataset_yaml} {users} {factorization} {rank} {noise} {seed} {round} {wandb_group} {task_id_value}'
    )


# ==================== å®éªŒè°ƒåº¦å‡½æ•° ====================
def run_experiment(config, gpus=None):
    """
    æ ¹æ®ç»™å®šå®éªŒé…ç½®å­—å…¸æ‰¹é‡ç”Ÿæˆå¹¶è¿è¡Œæ‰€æœ‰ä»»åŠ¡ç»„åˆã€‚

    é…ç½®å­—å…¸ä¸­éœ€è¦åŒ…å«çš„å¸¸ç”¨é”®ï¼š
        - exp_name: å®éªŒåç§°ï¼ˆç”¨äº wandb groupï¼‰ï¼›
        - seed_list: éšæœºç§å­åˆ—è¡¨ï¼›
        - dataset_list: æ•°æ®é›†åç§°åˆ—è¡¨ï¼›
        - factorization_list: åˆ†è§£æ–¹æ³•åˆ—è¡¨ï¼›
        - noise_list: DP å™ªå£°åˆ—è¡¨ï¼›
        - round: é€šä¿¡è½®æ•°ï¼›
        - num_users æˆ– num_users_list: å®¢æˆ·ç«¯æ•°é‡ï¼›
        - rank æˆ– rank_list: çŸ©é˜µåˆ†è§£ç§©ã€‚

    Args:
        config (dict): å®éªŒé…ç½®å­—å…¸ã€‚
        gpus (str | None): å¯è§ GPU åˆ—è¡¨å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ '0' æˆ– '0,1'ã€‚
    """
    if config is None:
        config = EXPERIMENT_CONFIG

    # è§£æ GPU åˆ—è¡¨å­—ç¬¦ä¸²ä¸ºåˆ—è¡¨ï¼Œä¾¿äºè½®è¯¢åˆ†é…
    gpu_list = None
    if gpus:
        gpu_list = [x.strip() for x in str(gpus).split(',') if x.strip() != '']
        if len(gpu_list) == 0:
            gpu_list = None

    # ä»é…ç½®ä¸­è¯»å–é€šç”¨å‚æ•°
    exp_name = config.get('exp_name')
    round_num = config.get('round', 20)
    users_list = config.get('num_users_list', [config.get('num_users', 10)])
    ranks = config.get('rank_list', [config.get('rank', 8)])

    # äº‹å…ˆç»Ÿè®¡æ€»ä»»åŠ¡æ•°ï¼Œä¾¿äºè¿›åº¦å±•ç¤º
    total_tasks = 0
    for seed in config['seed_list']:
        for dataset in config['dataset_list']:
            for users in users_list:
                for noise in config['noise_list']:
                    for factorization in config['factorization_list']:
                        for rank in ranks:
                            total_tasks += 1

    print(f"ğŸ“Š å®éªŒé…ç½®: {exp_name}")
    print(f"ğŸ“Š æ€»ä»»åŠ¡æ•°: {total_tasks}")
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œå®éªŒ...\n")

    # éå†æ‰€æœ‰ç»„åˆå¹¶é€ä¸ªè¿è¡Œ
    task_idx = 0
    for seed in config['seed_list']:
        for dataset in config['dataset_list']:
            for users in users_list:
                for noise in config['noise_list']:
                    for factorization in config['factorization_list']:
                        for rank in ranks:
                            task_idx += 1
                            # è½®è¯¢åˆ†é… GPUï¼šç¬¬ i ä¸ªä»»åŠ¡ä½¿ç”¨ gpu_list[(i-1) % len(gpu_list)]
                            gpu = None
                            if gpu_list:
                                gpu = gpu_list[(task_idx - 1) % len(gpu_list)]

                            print(
                                f"[{task_idx}/{total_tasks}] æ‰§è¡Œä»»åŠ¡: "
                                f"{dataset} | {factorization} | rank={rank} | "
                                f"noise={noise} | users={users} | seed={seed}"
                            )
                            if gpu:
                                print(f"   GPU: {gpu}")

                            task_id = f"[{task_idx}/{total_tasks}]"
                            run(
                                root, dataset, users, factorization, rank, noise, seed,
                                round=round_num, gpus=gpu, exp_name=exp_name, task_id=task_id
                            )

    print(f"\nâœ… å®éªŒæ‰§è¡Œå®Œæˆï¼å…±å®Œæˆ {total_tasks} ä¸ªä»»åŠ¡")


# ==================== æ•°æ®é›†ä¸æ—¥å¿—å·¥å…·å‡½æ•° ====================
def download_datasets(base_root, dataset_name):
    """
    ä¸‹è½½é¢„å®šä¹‰æ ‡å‡†æ•°æ®é›†ã€‚

    Args:
        base_root (str): æ•°æ®é›†ä¸‹è½½æ ¹ç›®å½•ã€‚
        dataset_name (str | list[str] | None): å•ä¸ªæ•°æ®é›†åã€åˆ—è¡¨æˆ– Noneã€‚
            - None: äº¤ç”±ä¸‹æ¸¸é€»è¾‘å†³å®šï¼›
            - str: å•ä¸ªæ•°æ®é›†ï¼›
            - list[str]: å¤šä¸ªæ•°æ®é›†ã€‚
    """
    if dataset_name is None:
        dataset_list = None
    elif isinstance(dataset_name, list):
        dataset_list = dataset_name
    else:
        dataset_list = [dataset_name]
    download_standard_datasets(base_root, dataset_list)


def clean_old_logs(log_dir='logs', dry_run=False):
    """
    æ¸…ç†é™ˆæ—§çš„æ—¥å¿—æ–‡ä»¶ï¼Œåªä¿ç•™ç›¸åŒå‚æ•°ç»„åˆä¸‹æœ€æ–°çš„ä¸€ä»½æ—¥å¿—ã€‚

    æ—¥å¿—ç›®å½•ç»“æ„é»˜è®¤çº¦å®šä¸ºï¼š
        logs/{dataset}/{factorization}/{rank}_{noise}_{seed}_{num_users}_{timestamp}.log

    å…¶ä¸­ï¼š
        - dataset      : æ•°æ®é›†åç§°ï¼ˆç›®å½•åï¼‰ï¼›
        - factorization: åˆ†è§£æ–¹æ³•åç§°ï¼ˆç›®å½•åï¼‰ï¼›
        - rank         : çŸ©é˜µåˆ†è§£ç§©ï¼›
        - noise        : DP å™ªå£°çº§åˆ«ï¼›
        - seed         : éšæœºç§å­ï¼›
        - num_users    : å®¢æˆ·ç«¯æ•°é‡ï¼›
        - timestamp    : æ—¶é—´æˆ³ï¼Œæ ¼å¼ä¸º YYYYMMDD_HHMMSSã€‚

    åŒä¸€ç»„ (dataset, factorization, rank, noise, seed, num_users) ä¸‹ï¼Œ
    åªä¿ç•™æ—¶é—´æˆ³æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶ï¼Œå…¶ä½™å…¨éƒ¨åˆ é™¤ã€‚

    Args:
        log_dir (str): æ—¥å¿—æ ¹ç›®å½•ï¼Œé»˜è®¤ä¸º 'logs'ã€‚
        dry_run (bool): è‹¥ä¸º Trueï¼Œåˆ™ä»…æ‰“å°å°†è¦åˆ é™¤çš„æ–‡ä»¶ï¼Œä¸å®é™…åˆ é™¤ã€‚

    Returns:
        dict: åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸ï¼š
            {
                'deleted': åˆ é™¤çš„æ–‡ä»¶æ•°é‡,
                'kept':    ä¿ç•™çš„æ–‡ä»¶æ•°é‡,
                'errors':  åˆ é™¤å¤±è´¥çš„æ•°é‡
            }
    """
    log_path = Path(log_dir)
    if not log_path.exists():
        print(f"âŒ æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {log_dir}")
        return {'deleted': 0, 'kept': 0, 'errors': 0}

    # æ—¥å¿—æ–‡ä»¶å‘½åæ ¼å¼ï¼š{rank}_{noise}_{seed}_{num_users}_{timestamp}.log
    # è·¯å¾„æ ¼å¼ï¼šlogs/{dataset}/{factorization}/{filename}.log
    log_pattern = re.compile(r'^(\d+)_([\d.]+)_(\d+)_(\d+)_(\d{8}_\d{6})\.log$')

    # ä»¥ (dataset, factorization, rank, noise, seed, num_users) ä¸ºåˆ†ç»„é”®
    log_groups = defaultdict(list)

    # éå†æ‰€æœ‰æ—¥å¿—æ–‡ä»¶å¹¶åˆ†ç»„
    for dataset_dir in log_path.iterdir():
        if not dataset_dir.is_dir():
            continue

        dataset_name = dataset_dir.name
        for factorization_dir in dataset_dir.iterdir():
            if not factorization_dir.is_dir():
                continue

            factorization_name = factorization_dir.name
            for log_file in factorization_dir.glob('*.log'):
                match = log_pattern.match(log_file.name)
                if match:
                    rank, noise, seed, num_users, timestamp = match.groups()
                    group_key = (dataset_name, factorization_name, rank, noise, seed, num_users)
                    log_groups[group_key].append((log_file, timestamp))
                else:
                    # è‹¥æ–‡ä»¶åæ ¼å¼ä¸ç¬¦åˆçº¦å®šï¼Œç»™å‡ºæç¤ºä½†ä¸å¼ºåˆ¶åˆ é™¤
                    print(f"âš ï¸  æ— æ³•è§£ææ—¥å¿—æ–‡ä»¶åæ ¼å¼: {log_file}")

    deleted_count = 0
    kept_count = 0
    error_count = 0

    # å¯¹æ¯ç»„æ—¥å¿—è¿›è¡Œæ¸…ç†ï¼šæŒ‰æ—¶é—´æˆ³æ’åºï¼Œä»…ä¿ç•™æœ€æ–°ä¸€ä»½
    for group_key, log_files in log_groups.items():
        dataset, factorization, rank, noise, seed, num_users = group_key

        if len(log_files) <= 1:
            # åªæœ‰ 0 æˆ– 1 ä¸ªæ–‡ä»¶æ—¶ï¼Œæ— éœ€æ¸…ç†
            kept_count += len(log_files)
            continue

        # æŒ‰æ—¶é—´æˆ³é™åºæ’åºï¼šæœ€æ–°çš„åœ¨å‰
        log_files.sort(key=lambda x: x[1], reverse=True)

        latest_file = log_files[0][0]
        kept_count += 1  # æœ€æ–°æ–‡ä»¶è¢«ä¿ç•™

        # åˆ é™¤è¯¥ç»„ä¸­å…¶ä»–æ—§æ—¥å¿—æ–‡ä»¶
        for log_file, timestamp in log_files[1:]:
            try:
                if dry_run:
                    print(f"  [DRY RUN] å°†åˆ é™¤: {log_file}")
                else:
                    log_file.unlink()
                    print(f"  âœ… å·²åˆ é™¤: {log_file}")
                deleted_count += 1
            except Exception as e:
                print(f"  âŒ åˆ é™¤å¤±è´¥ {log_file}: {e}")
                error_count += 1

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ—¥å¿—æ¸…ç†ç»Ÿè®¡:")
    print(f"   ä¿ç•™æ–‡ä»¶: {kept_count}")
    print(f"   åˆ é™¤æ–‡ä»¶: {deleted_count}")
    if error_count > 0:
        print(f"   é”™è¯¯æ•°é‡: {error_count}")

    return {
        'deleted': deleted_count,
        'kept': kept_count,
        'errors': error_count
    }


# ==================== å‘½ä»¤è¡Œå…¥å£ ====================
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Run SepFPL experiments")

    # -------------------- æ•°æ®é›†ç›¸å…³ --------------------
    parser.add_argument(
        "-d", "--download",
        action="store_true",
        help="ä¸‹è½½ Caltech-101ã€OxfordPetsã€OxfordFlowersã€Food-101ã€CIFAR-100 åˆ° root ç›®å½•"
    )

    # -------------------- å®éªŒæ‰§è¡Œæ¨¡å¼ --------------------
    parser.add_argument(
        "--exp1",
        action="store_true",
        help="æ‰§è¡Œå®éªŒ1ï¼ˆåŒ…å« Simple å’Œ Hard ä¸¤ä¸ªå­å®éªŒï¼‰"
    )
    parser.add_argument(
        "--exp2",
        action="store_true",
        help="æ‰§è¡Œå®éªŒ2ï¼ˆåŒ…å« Rank ä¸ HCSE/æ—¶é—´è‡ªé€‚åº”æ¶ˆèä¸¤ä¸ªå­å®éªŒï¼‰"
    )
    parser.add_argument(
        "-t", "--test",
        action="store_true",
        help="æµ‹è¯•å•ä¸ªä»»åŠ¡ï¼ˆéœ€é…åˆ --dataset / --users / --factorization / --rank / --noise / --seedï¼‰"
    )

    # -------------------- å•ä»»åŠ¡æµ‹è¯•å‚æ•° --------------------
    parser.add_argument("--dataset", type=str, help="æ•°æ®é›†åç§°ï¼Œä¾‹å¦‚ caltech-101")
    parser.add_argument("--users", type=int, help="å®¢æˆ·ç«¯æ•°é‡ï¼Œä¾‹å¦‚ 10")
    parser.add_argument("--factorization", type=str, help="åˆ†è§£æ–¹æ³•åç§°ï¼Œä¾‹å¦‚ sepfpl")
    parser.add_argument("--rank", type=int, help="çŸ©é˜µåˆ†è§£çš„ç§©ï¼Œä¾‹å¦‚ 8")
    parser.add_argument("--noise", type=float, help="å·®åˆ†éšç§å™ªå£°çº§åˆ«ï¼Œä¾‹å¦‚ 0.1")
    parser.add_argument("--seed", type=int, help="éšæœºç§å­ï¼Œä¾‹å¦‚ 1")
    parser.add_argument(
        "--round", type=int, default=10,
        help="è®­ç»ƒè½®æ¬¡ï¼ˆä»…ç”¨äºæµ‹è¯•æ¨¡å¼ï¼Œé»˜è®¤ 10ï¼‰"
    )

    # -------------------- ç³»ç»Ÿ/èµ„æºé…ç½® --------------------
    parser.add_argument(
        "--gpus", type=str, default='0,1',
        help="æŒ‡å®šå¯è§æ˜¾å¡ï¼Œå¦‚ '0' æˆ– '0,1'ï¼Œå¤šå¡å°†ç”¨äºè½®è¯¢åˆ†é…ä»»åŠ¡"
    )

    # -------------------- æ—¥å¿—ç®¡ç† --------------------
    parser.add_argument(
        "--clean-logs",
        action="store_true",
        help="æ¸…ç†é™ˆæ—§æ—¥å¿—æ–‡ä»¶ï¼Œä»…ä¿ç•™ç›¸åŒå‚æ•°ç»„åˆä¸‹æœ€æ–°çš„ä¸€ä»½æ—¥å¿—"
    )
    parser.add_argument(
        "--log-dir", type=str, default='logs',
        help="æ—¥å¿—æ–‡ä»¶æ ¹ç›®å½•ï¼ˆä¸ --clean-logs æ­é…ä½¿ç”¨ï¼‰"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ä»…æ˜¾ç¤ºå°†è¦åˆ é™¤çš„æ—¥å¿—æ–‡ä»¶ï¼Œä¸å®é™…åˆ é™¤ï¼ˆä¸ --clean-logs æ­é…ä½¿ç”¨ï¼‰"
    )

    # wandb é…ç½®è¯´æ˜ï¼š
    # å½“å‰è„šæœ¬ä¸å†é€šè¿‡å‘½ä»¤è¡Œå‚æ•°é…ç½® wandbï¼Œè€Œæ˜¯å®Œå…¨ä¾èµ–ç¯å¢ƒå˜é‡ï¼š
    #   - WANDB_MODE, WANDB_PROJECT, WANDB_ENTITY, WANDB_GROUP, WANDB_TAGS, WANDB_DIR ç­‰ï¼›
    #   - è®¾ç½® WANDB_DISABLED=1 å¯ä»¥å®Œå…¨ç¦ç”¨ wandbã€‚

    args = parser.parse_args()

    if args.clean_logs:
        # æ¸…ç†é™ˆæ—§æ—¥å¿—æ–‡ä»¶
        print("ğŸ§¹ å¼€å§‹æ¸…ç†é™ˆæ—§çš„æ—¥å¿—æ–‡ä»¶...")
        if args.dry_run:
            print("ğŸ” [DRY RUN æ¨¡å¼] ä»…é¢„è§ˆå°†è¢«åˆ é™¤çš„æ–‡ä»¶ï¼Œä¸ä¼šå®é™…åˆ é™¤\n")
        stats = clean_old_logs(log_dir=args.log_dir, dry_run=args.dry_run)
        if args.dry_run:
            print("\nğŸ’¡ æç¤º: å»æ‰ --dry-run å³å¯å®é™…æ‰§è¡Œåˆ é™¤æ“ä½œ")
        print("\nâœ… æ—¥å¿—æ¸…ç†å®Œæˆï¼")

    elif args.download:
        # ä¸‹è½½æ ‡å‡†æ•°æ®é›†
        download_datasets(root, ['caltech-101', 'oxford_pets', 'oxford_flowers', 'food-101', 'cifar-100'])

    elif args.exp1:
        # æ‰§è¡Œå®éªŒ 1ï¼ˆä¸»å®éªŒï¼‰
        print("ğŸš€ å¼€å§‹æ‰§è¡Œå®éªŒ1...")
        print("=" * 80)
        print("å®éªŒ1.1: Simple - æ ‡å‡†æ•°æ®é›† + 10 å®¢æˆ·ç«¯")
        print("=" * 80)
        run_experiment(EXPERIMENT_1_SIMPLE_CONFIG, gpus=args.gpus)

        print("\n" + "=" * 80)
        print("å®éªŒ1.2: Hard - CIFAR-100ï¼Œä¸åŒå®¢æˆ·ç«¯æ•°é‡")
        print("=" * 80)
        run_experiment(EXPERIMENT_1_HARD_CONFIG, gpus=args.gpus)
        print("\nâœ… å®éªŒ1æ‰§è¡Œå®Œæˆï¼")

    elif args.exp2:
        # æ‰§è¡Œå®éªŒ 2ï¼ˆæ¶ˆèå®éªŒï¼‰
        print("ğŸš€ å¼€å§‹æ‰§è¡Œå®éªŒ2...")
        print("=" * 80)
        print("å®éªŒ2.1: Rank æ¶ˆèå®éªŒï¼ˆä»… SepFPLï¼‰")
        print("=" * 80)
        run_experiment(EXPERIMENT_2_RANK_CONFIG, gpus=args.gpus)

        print("\n" + "=" * 80)
        print("å®éªŒ2.2: HCSE ä¸æ—¶é—´è‡ªé€‚åº”éšç§åˆ†é…æœºåˆ¶æ¶ˆèå®éªŒ")
        print("=" * 80)
        run_experiment(EXPERIMENT_2_ABLATION_CONFIG, gpus=args.gpus)
        print("\nâœ… å®éªŒ2æ‰§è¡Œå®Œæˆï¼")

    elif args.test:
        # å•ä»»åŠ¡æµ‹è¯•æ¨¡å¼
        required_params = ['dataset', 'users', 'factorization', 'rank', 'noise', 'seed']
        missing_params = [p for p in required_params if getattr(args, p) is None]
        if missing_params:
            print(f"âŒ é”™è¯¯ï¼šæµ‹è¯•ä»»åŠ¡ç¼ºå°‘ä»¥ä¸‹å‚æ•°: {', '.join(missing_params)}")
            print("\nç¤ºä¾‹ç”¨æ³•:")
            print("  python run_main.py -t --dataset caltech-101 --users 10 --factorization sepfpl --rank 8 --noise 0.1 --seed 1")
            print("  python run_main.py -t --dataset caltech-101 --users 10 --factorization sepfpl --rank 8 --noise 0.1 --seed 1 --round 5 --gpus 0")
        else:
            print("ğŸ§ª æµ‹è¯•å•ä¸ªä»»åŠ¡...")
            print(f"   æ•°æ®é›†: {args.dataset}")
            print(f"   å®¢æˆ·ç«¯æ•°: {args.users}")
            print(f"   åˆ†è§£æ–¹æ³•: {args.factorization}")
            print(f"   Rank: {args.rank}")
            print(f"   å™ªå£°çº§åˆ«: {args.noise}")
            print(f"   éšæœºç§å­: {args.seed}")
            print(f"   è®­ç»ƒè½®æ¬¡: {args.round}")
            if args.gpus:
                print(f"   GPU: {args.gpus}")

            print("   Wandb: é€šè¿‡ç¯å¢ƒå˜é‡è‡ªåŠ¨é…ç½®\n")

            # è‹¥æŒ‡å®šäº†å¤šå¼ å¡ï¼Œæµ‹è¯•æ¨¡å¼ä»…ä½¿ç”¨åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å¼ 
            gpu_for_test = None
            if args.gpus:
                gpu_list = [x.strip() for x in str(args.gpus).split(',') if x.strip() != '']
                if len(gpu_list) > 0:
                    gpu_for_test = gpu_list[0]

            run(
                root, args.dataset, args.users, args.factorization,
                args.rank, args.noise, args.seed, args.round, gpu_for_test,
                exp_name=None, task_id=None  # æµ‹è¯•ä»»åŠ¡ä¸ä½¿ç”¨ exp_name å’Œ task_id
            )
            print("\nâœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼")

    else:
        # æ— ä»»ä½•å­å‘½ä»¤æ—¶ï¼Œè¾“å‡ºå¯ç”¨é€‰é¡¹æ¦‚è§ˆ
        print("æœªæŒ‡å®šæ“ä½œã€‚å¯ç”¨é€‰é¡¹å¦‚ä¸‹ï¼š")
        print("  --download    : ä¸‹è½½æ ‡å‡†æ•°æ®é›†")
        print("  --exp1        : æ‰§è¡Œå®éªŒ1ï¼ˆSimple + Hardï¼‰")
        print("  --exp2        : æ‰§è¡Œå®éªŒ2ï¼ˆRank + Ablationï¼‰")
        print("  --test        : æµ‹è¯•å•ä¸ªä»»åŠ¡ï¼ˆéœ€é…åˆå‚æ•°ï¼‰")
        print("  --clean-logs  : æ¸…ç†é™ˆæ—§æ—¥å¿—ï¼Œä»…ä¿ç•™æœ€æ–°æ—¥å¿—")
        print("  --dry-run     : ä¸ --clean-logs æ­é…ï¼Œä»…é¢„è§ˆå¾…åˆ æ–‡ä»¶")
