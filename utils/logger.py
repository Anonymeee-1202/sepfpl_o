import os
import sys
from pathlib import Path
from datetime import datetime
from typing import Any, Dict, Optional
from loguru import logger

_LOG_TAG_FIELD = "_log_tag"

_GLOBAL_LOGGER = None

def init_logger_from_args(
    args: Optional[Any] = None,
    log_dir: str = "logs",
    level: str = "INFO",
    log_to_file: bool = True,
    log_to_console: bool = True,
    force_reinit: bool = False,
    context_extra: Optional[Dict[str, Any]] = None,
    **kwargs
):
    """
    åˆå§‹åŒ–å…¨å±€ Loggerã€‚æ”¯æŒè‡ªåŠ¨ä» args æå–ä¸Šä¸‹æ–‡ã€ç›®å½•è‡ªåŠ¨åˆ›å»ºã€æ—¥å¿—è½®è½¬ä¸å‹ç¼©ã€‚
    
    Args:
        dataset_name, method_name, exp_name_override: å¯é€šè¿‡ kwargs ä¼ å…¥ä»¥è¦†ç›–é»˜è®¤å€¼ã€‚
    """
    global _GLOBAL_LOGGER
    if _GLOBAL_LOGGER is not None and not force_reinit:
        return _GLOBAL_LOGGER

    # --- 1. ä¸Šä¸‹æ–‡æ„å»º (Priority: extra > args) ---
    keys = ["task_id", "factorization", "rank", "noise", "round", "num_users", "seed", "sepfpl_topk", "rdp_p"]
    context = {k: getattr(args, k) for k in keys if hasattr(args, k)}
    if context_extra:
        context.update(context_extra)

    # --- 2. ç¡®å®šå…ƒæ•°æ® (Priority: kwargs > context > args > default) ---
    def get_val(key, arg_attr, default, fallback=None):
        if key in kwargs and kwargs.get(key) is not None:
            return kwargs.get(key)
        value = context.get(arg_attr)
        if value not in [None, ""]:
            return value
        if args and hasattr(args, arg_attr):
            return getattr(args, arg_attr)
        if fallback is not None:
            return fallback(args) if callable(fallback) else fallback
        return default

    def infer_dataset_from_args(a):
        if a is None:
            return "default_ds"
        if hasattr(a, "dataset_config_file") and a.dataset_config_file:
            base = os.path.basename(a.dataset_config_file)
            name, _ = os.path.splitext(base)
            return name
        if hasattr(a, "dataset"):
            return a.dataset
        return "default_ds"

    dataset = get_val("dataset_name", "dataset", "default_ds", fallback=infer_dataset_from_args)
    method = get_val("method_name", "factorization", "default_method")
    rank_val = get_val("rank_value", "rank", None)
    noise_val = get_val("noise_value", "noise", None)
    users_val = (
        kwargs.get("num_users")
        or context.get("num_users")
        or getattr(args, "num_users", None)
        or getattr(args, "users", None)
        or None
    )
    task_id = context.get("task_id") or (getattr(args, "task_id", None) if args else None) or "task"
    
    # è·å– seed å€¼
    seed_val = (
        kwargs.get("seed")
        or context.get("seed")
        or (getattr(args, "seed", None) if args else None)
        or None
    )
    
    # è·å– sepfpl_topk å’Œ rdp_pï¼ˆä»…å¯¹ sepfpl ç›¸å…³æ–¹æ³•ï¼‰
    sepfpl_methods = ['sepfpl', 'sepfpl_time_adaptive', 'sepfpl_hcse']
    is_sepfpl = method in sepfpl_methods
    
    sepfpl_topk_val = None
    rdp_p_val = None
    if is_sepfpl:
        sepfpl_topk_val = (
            kwargs.get("sepfpl_topk")
            or context.get("sepfpl_topk")
            or (getattr(args, "sepfpl_topk", None) if args else None)
        )
        rdp_p_val = (
            kwargs.get("rdp_p")
            or context.get("rdp_p")
            or (getattr(args, "rdp_p", None) if args else None)
        )
    
    # è·å– wandb_groupï¼ˆç”¨äºæ—¥å¿—ç›®å½•ç»„ç»‡ï¼‰
    wandb_group = (
        kwargs.get("wandb_group")
        or (getattr(args, "wandb_group", None) if args else None)
        or "default"
    )
    
    # å®éªŒåé€»è¾‘: æŒ‡å®š > (rank_noise) > logger_name
    default_exp = f"{getattr(args, 'rank', 'r')}_{getattr(args, 'noise', 'n')}" if args else "experiment"
    exp_name = kwargs.get("exp_name_override") or context.get("logger_name") or default_exp

    # æ„å»º log_tagï¼Œä½¿ç”¨å•å­—æ¯æ ‡è¯†ç¬¦
    # æ ¼å¼: {dataset}_{method}_r{rank}_n{noise}_s{seed}_k{topk}_p{rdp_p}_u{users}_{task_id}
    log_tag_parts = [dataset, method]
    
    # æ·»åŠ  rank (r)
    if rank_val is not None:
        log_tag_parts.append(f"r{rank_val}")
    
    # æ·»åŠ  noise (n)
    if noise_val is not None:
        log_tag_parts.append(f"n{noise_val}")
    
    # æ·»åŠ  seed (s)
    if seed_val is not None:
        log_tag_parts.append(f"s{seed_val}")
    
    # å¦‚æœæ˜¯ sepfpl ç›¸å…³æ–¹æ³•ï¼Œæ·»åŠ  topk (k) å’Œ rdp_p (p)
    if is_sepfpl:
        if sepfpl_topk_val is not None:
            log_tag_parts.append(f"k{sepfpl_topk_val}")
        if rdp_p_val is not None:
            # ä¿ç•™ rdp_p ä¸­çš„ç‚¹å·ï¼Œä¸æ›¿æ¢
            log_tag_parts.append(f"p{rdp_p_val}")
    
    # æ·»åŠ  users (u) å’Œ task_id
    if users_val is not None:
        log_tag_parts.append(f"u{users_val}")
    log_tag_parts.append(task_id)
    
    log_tag = "_".join(log_tag_parts)
    context[_LOG_TAG_FIELD] = log_tag

    # --- 3. é…ç½® Loguru ---
    logger.remove()
    
    # Console Sink
    if log_to_console:
        fmt = (
            "<green>{time:HH:mm:ss}</green> | "
            "<level>{level}</level> | "
            "<cyan>{extra[_log_tag]}</cyan> | "
            "<level>{message}</level>"
        )
        logger.add(sys.stdout, format=fmt, level=level, colorize=True)

    # File Sink
    if log_to_file:
        # æ—¥å¿—ç›®å½•ç»“æ„: log_dir / wandb_group / dataset / method
        log_path = Path(log_dir) / str(wandb_group) / str(dataset) / str(method)
        log_path.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ sepfpl ç›¸å…³æ–¹æ³•ï¼Œå¦‚æœæ˜¯åˆ™æ·»åŠ  topk å’Œ rdp_p å‚æ•°
        sepfpl_methods = ['sepfpl', 'sepfpl_time_adaptive', 'sepfpl_hcse']
        is_sepfpl = method in sepfpl_methods
        
        # åŸºç¡€æ–‡ä»¶åéƒ¨åˆ†
        filename_parts = [rank_val, noise_val]
        
        # å¦‚æœæ˜¯ sepfpl ç›¸å…³æ–¹æ³•ï¼Œæ·»åŠ  topk å’Œ rdp_p
        if is_sepfpl:
            sepfpl_topk = (
                kwargs.get("sepfpl_topk")
                or context.get("sepfpl_topk")
                or (getattr(args, "sepfpl_topk", None) if args else None)
            )
            rdp_p = (
                kwargs.get("rdp_p")
                or context.get("rdp_p")
                or (getattr(args, "rdp_p", None) if args else None)
            )
            
            if sepfpl_topk is not None:
                filename_parts.append(sepfpl_topk)  # ç›´æ¥æ·»åŠ æ•°å­—ï¼Œä¸åŠ å‰ç¼€
            if rdp_p is not None:
                # ç›´æ¥ä½¿ç”¨ rdp_p çš„å­—ç¬¦ä¸²å½¢å¼ï¼Œä¿ç•™åŸå§‹æ ¼å¼ï¼ˆåŒ…å«ç‚¹å·ï¼‰
                filename_parts.append(str(rdp_p))
        
        # æ·»åŠ  users å’Œ timestamp
        filename_parts.extend([users_val, timestamp])
        
        # æ–‡ä»¶åæ ¼å¼: {rank}_{noise}_{[topkX]}_{[rdpY]}_{users}_{timestamp}.log
        log_file = log_path / f"{'_'.join(map(str, filename_parts))}.log"
        
        fmt_file = (
            "{time:YYYY-MM-DD HH:mm:ss} | "
            "{level} | "
            "{extra[_log_tag]} | "
            "{message}"
        )
        logger.add(str(log_file), format=fmt_file, level=level, rotation="500 MB", retention="30 days", compression="zip")
        print(f"ğŸ“‹ Log file: {log_file}")

    # --- 4. ç»‘å®šä¸Šä¸‹æ–‡å¹¶ä¿å­˜ ---
    _GLOBAL_LOGGER = logger.bind(**context)
    return _GLOBAL_LOGGER

# --- è¾…åŠ©æ¥å£ ---

def get_experiment_logger(*args, **kwargs):
    """init_logger_from_args çš„åˆ«å"""
    return init_logger_from_args(*args, **kwargs)

def get_global_logger():
    """è·å–å…¨å±€å®ä¾‹ï¼Œæœªåˆå§‹åŒ–è¿”å› None"""
    return _GLOBAL_LOGGER

def require_global_logger():
    """è·å–å…¨å±€å®ä¾‹ï¼Œæœªåˆå§‹åŒ–æŠ›å‡ºå¼‚å¸¸"""
    if _GLOBAL_LOGGER is None:
        raise RuntimeError("Global logger not initialized. Call init_logger_from_args() first.")
    return _GLOBAL_LOGGER