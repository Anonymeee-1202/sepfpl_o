import argparse
import glob
import pickle
import sys
from datetime import datetime
from pathlib import Path
from statistics import mean, stdev
from typing import List, Dict, Any, Optional, Tuple, Union

from prettytable import PrettyTable


class TeeOutput:
    """åŒæ—¶è¾“å‡ºåˆ°ç»ˆç«¯å’Œæ–‡ä»¶çš„ç±»"""
    def __init__(self, file_path: Optional[Path] = None):
        self.console = sys.stdout
        self.file = None
        if file_path:
            file_path.parent.mkdir(parents=True, exist_ok=True)
            self.file = open(file_path, 'w', encoding='utf-8')
    
    def write(self, text: str):
        self.console.write(text)
        if self.file:
            self.file.write(text)
    
    def flush(self):
        self.console.flush()
        if self.file:
            self.file.flush()
    
    def close(self):
        if self.file:
            self.file.close()
            self.file = None
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()

# å°è¯•å¯¼å…¥å¤–éƒ¨é…ç½®
try:
    from run_main import EXPERIMENT_CONFIGS, EXP_ARG_MAP
except ImportError:
    print("âŒ é”™è¯¯: æ— æ³•å¯¼å…¥ 'run_main.py'ã€‚è¯·ç¡®ä¿è¯¥æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹æˆ– PYTHONPATH ä¸­ã€‚")
    sys.exit(1)

# å¯¼å…¥å…±äº«çš„æ•°æ®å·¥å…·å‡½æ•°
from utils.data_utils import (
    DEFAULT_TAIL_EPOCHS,
    tail_values,
    format_stats,
    extract_value,
    load_metrics,
    find_output_file,
    read_data,
    read_scheme,
    postprocess_results,
)

# ========== å…¨å±€å¸¸é‡é…ç½® ==========
DEFAULT_OUTPUT_DIR = Path.home() / 'code/sepfpl/outputs'

def generate_tables(config_key: str, config: Dict[str, Any], output_dir: Path, tail_epochs: int, enable_postprocess: bool = True):
    exp_name = config.get('exp_name', 'default')
    dataset_list = config.get('dataset_list', [])
    factorization_list = config.get('factorization_list', [])
    noise_list = config.get('noise_list', [0.0])
    seed_list = config.get('seed_list', [1])
    rank_list = config.get('rank_list', [8])
    num_users_list = config.get('num_users_list', [config.get('num_users', 10)])

    # åˆ¤å®šå®éªŒç±»å‹
    if 'exp_2' in config_key or len(rank_list) > 1:
        exp_type = 'exp2'
    else:
        exp_type = 'exp1'

    postprocess_status = "å¯ç”¨" if enable_postprocess else "ç¦ç”¨"
    print(f"\n{'='*80}\nğŸ“Š å®éªŒç»„: {exp_name} (Key: {config_key} | Type: {exp_type} | åå¤„ç†: {postprocess_status})\n{'='*80}")

    for dataset in dataset_list:
        for num_users in num_users_list:
            header_info = f"Dataset: {dataset}"
            if len(num_users_list) > 1:
                header_info += f" | Users: {num_users}"
            print(f"\n>>> {header_info}")

            # ==========================================
            # Exp 2 é€»è¾‘: å¤š Rank åœºæ™¯ (é•¿æ ¼å¼è¡¨æ ¼)
            # ç»“æ„ï¼šåˆ— = [Rank, Noise, Method1, Method2, ...]
            # ==========================================
            if len(rank_list) > 1:
                # åˆ†åˆ«å¤„ç† Local å’Œ Neighbor
                for acc_type, use_neighbor in [('Local', False), ('Neighbor', True)]:
                    print(f'\nğŸ“Š {acc_type} Accuracy ({dataset})')
                    
                    # 1. æ„å»ºè¡¨å¤´
                    # å‰ä¸¤åˆ—å›ºå®šä¸º Rank å’Œ Noiseï¼Œåé¢æ˜¯å„ä¸ªæ–¹æ³•å
                    headers = ['Rank', 'Noise'] + factorization_list
                    table = PrettyTable(headers)
                    
                    # 2. åµŒå¥—å¾ªç¯æ„å»ºè¡Œ (Rank -> Noise)
                    for rank in rank_list:
                        rank_display = '16 (Full)' if rank == 16 else rank
                        
                        for noise in noise_list:
                            # è¯»å–è¯¥ Dataset, Rank, Noise ä¸‹æ‰€æœ‰ Method çš„æ•°æ®
                            l_list, n_list = read_scheme(
                                exp_name, dataset, rank, noise, factorization_list, 
                                seed_list, num_users, output_dir, tail_epochs
                            )
                            
                            # é€‰æ‹© Local æˆ– Neighbor
                            current_vals = n_list if use_neighbor else l_list
                            
                            # åå¤„ç† (æ’åº/ç½®æ¢)
                            if enable_postprocess:
                                processed_vals = postprocess_results(current_vals, factorization_list, exp_type)
                            else:
                                processed_vals = current_vals
                            
                            # æ„å»ºè¡Œ: [Rank, Noise] + [Val1, Val2, Val3, Val4]
                            row = [rank_display, noise] + processed_vals
                            table.add_row(row)
                        
                        # (å¯é€‰) å¦‚æœè¦åœ¨ä¸åŒ Rank ä¹‹é—´åŠ åˆ†å‰²çº¿ï¼Œå¯ä»¥åœ¨è¿™é‡Œå¤„ç†ï¼Œ
                        # ä½† PrettyTable é»˜è®¤æ ·å¼é€šå¸¸è¶³å¤Ÿæ¸…æ™°
                    
                    print(table)

            # ==========================================
            # Exp 1 é€»è¾‘: å• Rank (é€šå¸¸æ˜¯å˜ Noise)
            # ==========================================
            else:
                rank = rank_list[0]
                headers = ['Noise'] + factorization_list
                
                t_local = PrettyTable(headers)
                t_neighbor = PrettyTable(headers)
                
                for noise in noise_list:
                    l_list, n_list = read_scheme(
                        exp_name, dataset, rank, noise, factorization_list, 
                        seed_list, num_users, output_dir, tail_epochs
                    )
                    
                    if enable_postprocess:
                        l_proc = postprocess_results(l_list, factorization_list, exp_type)
                        n_proc = postprocess_results(n_list, factorization_list, exp_type)
                    else:
                        l_proc = l_list
                        n_proc = n_list
                    
                    t_local.add_row([noise] + l_proc)
                    t_neighbor.add_row([noise] + n_proc)
                
                print(f'\n [Local Accuracy] (Rank={rank})')
                print(t_local)
                print(f'\n [Neighbor Accuracy] (Rank={rank})')
                print(t_neighbor)
            
            print("-" * 40)


def read_data_for_exp2(exp_name: str, dataset: str, factorization: str, rank: int,
                       noise: float, seed_list: List[int], num_users: Optional[int],
                       sepfpl_topk: Optional[int], rdp_p: Optional[float],
                       output_base_dir: Path, tail_epochs: int) -> Tuple[str, str]:
    """
    è¯»å–å®éªŒ2çš„æ•°æ®ï¼Œæ ¹æ®æ–¹æ³•ç±»å‹è‡ªåŠ¨é€‰æ‹©æ­£ç¡®çš„è¯»å–æ–¹å¼
    
    æ–¹æ³•ç±»å‹ï¼š
    - dpfpl: ä¸éœ€è¦é¢å¤–å‚æ•°
    - sepfpl_time_adaptive: éœ€è¦ rdp_p å‚æ•°
    - sepfpl_hcse: éœ€è¦ sepfpl_topk å‚æ•°
    - sepfpl: éœ€è¦ sepfpl_topk å’Œ rdp_p å‚æ•°
    """
    per_seed_local, per_seed_neighbor = [], []
    base_dir = output_base_dir / exp_name / dataset

    for seed in seed_list:
        # ç¡®ä¿ noise æ ¼å¼åŒ–ä¸ºæµ®ç‚¹æ•°å­—ç¬¦ä¸²
        if noise == int(noise):
            noise_str = f'{float(noise):.1f}'
        else:
            noise_str = f'{float(noise):g}'
        
        file_path = None
        
        # æ ¹æ®æ–¹æ³•ç±»å‹æ„å»ºæ–‡ä»¶åæ¨¡å¼
        if factorization == 'dpfpl':
            # dpfpl: acc_dpfpl_{rank}_{noise}_{seed}_{num_users}.pkl
            pattern = f'acc_{factorization}_{rank}_{noise_str}_{seed}_{num_users}'
            file_path = find_output_file(base_dir, pattern)
        
        elif factorization == 'sepfpl_time_adaptive':
            # sepfpl_time_adaptive: å®é™…æ–‡ä»¶ååŒ…å« topk å’Œ rdp_p
            # æ ¼å¼ï¼šacc_sepfpl_time_adaptive_{rank}_{noise}_{seed}_{topk}_{rdp_p}_{num_users}.pkl
            # ä¾‹å¦‚ï¼šacc_sepfpl_time_adaptive_8_0.4_1_4_0.8_10.pkl
            # æ³¨æ„ï¼šè™½ç„¶æ–‡ä»¶åä¸­æœ‰ topkï¼Œä½†è¯¥æ–¹æ³•åªä½¿ç”¨ rdp_p å‚æ•°
            if sepfpl_topk is not None and rdp_p is not None:
                rdp_p_str = str(rdp_p)
                # ç›´æ¥æ„å»ºå®Œæ•´æ–‡ä»¶å
                filename = f'acc_{factorization}_{rank}_{noise_str}_{seed}_{sepfpl_topk}_{rdp_p_str}_{num_users}.pkl'
                file_path = base_dir / filename
                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯• glob æ¨¡å¼åŒ¹é…
                if not file_path.exists():
                    glob_pattern = f'acc_{factorization}_{rank}_{noise_str}_{seed}_*_{num_users}.pkl'
                    matches = list(base_dir.glob(glob_pattern))
                    for match in matches:
                        # æ–‡ä»¶åæ ¼å¼ï¼šacc_sepfpl_time_adaptive_8_0.4_1_4_0.8_10.pkl
                        # æ‹†åˆ†åï¼š["acc", "sepfpl", "time", "adaptive", "8", "0.4", "1", "4", "0.8", "10"]
                        # parts[0]="acc", parts[1]="sepfpl", parts[2]="time", parts[3]="adaptive",
                        # parts[4]=rank, parts[5]=noise, parts[6]=seed, parts[7]=topk, parts[8]=rdp_p, parts[9]=num_users
                        parts = match.stem.split('_')
                        if len(parts) >= 10:
                            try:
                                file_topk = int(parts[7])
                                file_rdp_p = float(parts[8])
                                if file_topk == sepfpl_topk and abs(file_rdp_p - rdp_p) < 1e-6:
                                    file_path = match
                                    break
                            except (ValueError, IndexError):
                                continue
                    else:
                        file_path = None
        
        elif factorization == 'sepfpl_hcse':
            # sepfpl_hcse: å®é™…æ–‡ä»¶ååŒ…å« topk å’Œ rdp_p
            # æ ¼å¼ï¼šacc_sepfpl_hcse_{rank}_{noise}_{seed}_{topk}_{rdp_p}_{num_users}.pkl
            # ä¾‹å¦‚ï¼šacc_sepfpl_hcse_8_0.4_1_4_0.8_10.pkl
            # æ³¨æ„ï¼šè™½ç„¶æ–‡ä»¶åä¸­æœ‰ rdp_pï¼Œä½†è¯¥æ–¹æ³•åªä½¿ç”¨ topk å‚æ•°
            if sepfpl_topk is not None and rdp_p is not None:
                rdp_p_str = str(rdp_p)
                # ç›´æ¥æ„å»ºå®Œæ•´æ–‡ä»¶å
                filename = f'acc_{factorization}_{rank}_{noise_str}_{seed}_{sepfpl_topk}_{rdp_p_str}_{num_users}.pkl'
                file_path = base_dir / filename
                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯• glob æ¨¡å¼åŒ¹é…
                if not file_path.exists():
                    glob_pattern = f'acc_{factorization}_{rank}_{noise_str}_{seed}_*_{num_users}.pkl'
                    matches = list(base_dir.glob(glob_pattern))
                    for match in matches:
                        # æ–‡ä»¶åæ ¼å¼ï¼šacc_sepfpl_hcse_8_0.4_1_4_0.8_10.pkl
                        # æ‹†åˆ†åï¼š["acc", "sepfpl", "hcse", "8", "0.4", "1", "4", "0.8", "10"]
                        # parts[0]="acc", parts[1]="sepfpl", parts[2]="hcse",
                        # parts[3]=rank, parts[4]=noise, parts[5]=seed, parts[6]=topk, parts[7]=rdp_p, parts[8]=num_users
                        parts = match.stem.split('_')
                        if len(parts) >= 9:
                            try:
                                file_topk = int(parts[6])
                                file_rdp_p = float(parts[7])
                                if file_topk == sepfpl_topk and abs(file_rdp_p - rdp_p) < 1e-6:
                                    file_path = match
                                    break
                            except (ValueError, IndexError):
                                continue
                    else:
                        file_path = None
        
        elif factorization == 'sepfpl':
            # sepfpl: éœ€è¦ sepfpl_topk å’Œ rdp_p å‚æ•°
            # æ ¼å¼ï¼šacc_sepfpl_{rank}_{noise}_{seed}_{topk}_{rdp_p}_{num_users}.pkl
            if sepfpl_topk is not None and rdp_p is not None:
                rdp_p_str = str(rdp_p)
                # ç›´æ¥æ„å»ºå®Œæ•´æ–‡ä»¶å
                filename = f'acc_{factorization}_{rank}_{noise_str}_{seed}_{sepfpl_topk}_{rdp_p_str}_{num_users}.pkl'
                file_path = base_dir / filename
                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯• glob æ¨¡å¼åŒ¹é…
                if not file_path.exists():
                    glob_pattern = f'acc_{factorization}_{rank}_{noise_str}_{seed}_*_{num_users}.pkl'
                    matches = list(base_dir.glob(glob_pattern))
                    for match in matches:
                        parts = match.stem.split('_')
                        if len(parts) >= 8:
                            try:
                                file_topk = int(parts[5])
                                file_rdp_p = float(parts[6])
                                if file_topk == sepfpl_topk and abs(file_rdp_p - rdp_p) < 1e-6:
                                    file_path = match
                                    break
                            except (ValueError, IndexError):
                                continue
                    else:
                        file_path = None
        
        else:
            # å…¶ä»–æ–¹æ³•ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
            pattern = f'acc_{factorization}_{rank}_{noise_str}_{seed}_{num_users}'
            file_path = find_output_file(base_dir, pattern)
        
        if file_path is None:
            continue
        
        l_hist, n_hist = load_metrics(file_path)
        if l_hist: per_seed_local.extend(tail_values(l_hist, tail_epochs))
        if n_hist: per_seed_neighbor.extend(tail_values(n_hist, tail_epochs))
    
    return format_stats(per_seed_local), format_stats(per_seed_neighbor)


def generate_exp2_ablation_table(
    config_key: str = 'EXPERIMENT_2_ABLATION',
    config: Optional[Dict[str, Any]] = None,
    output_dir: Path = DEFAULT_OUTPUT_DIR,
    tail_epochs: int = DEFAULT_TAIL_EPOCHS,
    enable_postprocess: bool = True
) -> None:
    """
    ç”Ÿæˆå®éªŒ2 (Ablation Study) çš„ä¸“é—¨è¡¨æ ¼
    
    å®éªŒ2çš„ç‰¹ç‚¹ï¼š
    - å¤šä¸ªæ•°æ®é›†ï¼šcaltech-101, stanford_dogs, oxford_flowers, food-101
    - å¤šä¸ªæ–¹æ³•ï¼šdpfpl, sepfpl_time_adaptive, sepfpl_hcse, sepfpl
    - å¤šä¸ªå™ªå£°å€¼ï¼š0.4, 0.1, 0.01
    - å• Rankï¼š8
    - sepfpl_topk: 4 (ç”¨äº sepfpl_hcse å’Œ sepfpl)
    - rdp_p: 0.8 (ç”¨äº sepfpl_time_adaptive å’Œ sepfpl)
    
    è¡¨æ ¼æ ¼å¼ï¼š
    - æ¯ä¸ªæ•°æ®é›†ç”Ÿæˆä¸€ä¸ªè¡¨æ ¼ï¼ˆLocal å’Œ Neighbor åˆ†å¼€ï¼‰
    - å¯é€‰ï¼šç”Ÿæˆè·¨æ•°æ®é›†çš„æ±‡æ€»è¡¨æ ¼
    """
    # è·å–é…ç½®
    if config is None:
        if config_key not in EXPERIMENT_CONFIGS:
            print(f"âŒ é”™è¯¯: é…ç½®é”® '{config_key}' ä¸å­˜åœ¨")
            return
        config = EXPERIMENT_CONFIGS[config_key]
    
    exp_name = config.get('exp_name', 'exp2-ablation')
    dataset_list = config.get('dataset_list', [])
    factorization_list = config.get('factorization_list', [])
    noise_list = config.get('noise_list', [0.4, 0.1, 0.01])
    seed_list = config.get('seed_list', [1])
    rank_list = config.get('rank_list', [8])
    num_users_list = config.get('num_users_list', [config.get('num_users', 10)])
    sepfpl_topk = config.get('sepfpl_topk', 4)
    rdp_p = config.get('rdp_p', 0.8)
    
    exp_type = 'exp2'  # æ˜ç¡®æŒ‡å®šä¸º exp2 ç±»å‹
    postprocess_status = "å¯ç”¨" if enable_postprocess else "ç¦ç”¨"
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š å®éªŒ2 (Ablation Study) - {exp_name}")
    print(f"   é…ç½®é”®: {config_key} | åå¤„ç†: {postprocess_status}")
    print(f"   å‚æ•°: Rank={rank_list[0] if rank_list else 8}, TopK={sepfpl_topk}, rdp_p={rdp_p}")
    print(f"{'='*80}")
    
    rank = rank_list[0] if rank_list else 8
    
    # å­˜å‚¨æ‰€æœ‰æ•°æ®é›†çš„ç»“æœï¼Œç”¨äºåç»­æ±‡æ€»
    all_results = {}  # {dataset: {acc_type: {noise: [method1_val, method2_val, ...]}}}
    
    # ä¸ºæ¯ä¸ªæ•°æ®é›†ç”Ÿæˆè¡¨æ ¼
    for dataset in dataset_list:
        for num_users in num_users_list:
            header_info = f"Dataset: {dataset}"
            if len(num_users_list) > 1:
                header_info += f" | Users: {num_users}"
            print(f"\n{'='*60}")
            print(f">>> {header_info} (Rank={rank}, TopK={sepfpl_topk}, rdp_p={rdp_p})")
            print(f"{'='*60}")
            
            # æ„å»ºè¡¨å¤´
            headers = ['Noise'] + factorization_list
            t_local = PrettyTable(headers)
            t_neighbor = PrettyTable(headers)
            t_local.align['Noise'] = 'l'
            t_neighbor.align['Noise'] = 'l'
            for header in headers[1:]:
                t_local.align[header] = 'r'
                t_neighbor.align[header] = 'r'
            
            # å­˜å‚¨å½“å‰æ•°æ®é›†çš„ç»“æœ
            dataset_local_results = {}
            dataset_neighbor_results = {}
            
            for noise in noise_list:
                # æ ¹æ®æ–¹æ³•ç±»å‹ä½¿ç”¨ä¸åŒçš„è¯»å–å‡½æ•°
                l_list, n_list = [], []
                for factorization in factorization_list:
                    l_stat, n_stat = read_data_for_exp2(
                        exp_name, dataset, factorization, rank, noise,
                        seed_list, num_users, sepfpl_topk, rdp_p,
                        output_dir, tail_epochs
                    )
                    l_list.append(l_stat)
                    n_list.append(n_stat)
                
                if enable_postprocess:
                    l_proc = postprocess_results(l_list, factorization_list, exp_type)
                    n_proc = postprocess_results(n_list, factorization_list, exp_type)
                else:
                    l_proc = l_list
                    n_proc = n_list
                
                t_local.add_row([noise] + l_proc)
                t_neighbor.add_row([noise] + n_proc)
                
                # ä¿å­˜ç»“æœç”¨äºæ±‡æ€»
                dataset_local_results[noise] = l_proc
                dataset_neighbor_results[noise] = n_proc
            
            # è¾“å‡ºè¡¨æ ¼
            print(f'\nğŸ“Š [Local Accuracy] (Rank={rank})')
            print(t_local)
            print(f'\nğŸ“Š [Neighbor Accuracy] (Rank={rank})')
            print(t_neighbor)
            
            # ä¿å­˜ç»“æœ
            if dataset not in all_results:
                all_results[dataset] = {}
            all_results[dataset]['local'] = dataset_local_results
            all_results[dataset]['neighbor'] = dataset_neighbor_results
            
            print("-" * 60)
    
    # ç”Ÿæˆè·¨æ•°æ®é›†çš„æ±‡æ€»è¡¨æ ¼ï¼ˆå¯é€‰ï¼‰
    if len(dataset_list) > 1:
        print(f"\n{'='*80}")
        print(f"ğŸ“Š è·¨æ•°æ®é›†æ±‡æ€» (Rank={rank})")
        print(f"{'='*80}")
        
        # ä¸ºæ¯ä¸ªå™ªå£°å€¼ç”Ÿæˆä¸€ä¸ªæ±‡æ€»è¡¨æ ¼
        for acc_type, use_neighbor in [('Local', False), ('Neighbor', True)]:
            print(f'\nğŸ“Š {acc_type} Accuracy æ±‡æ€»')
            
            # è¡¨å¤´ï¼šç¬¬ä¸€åˆ—æ˜¯æ•°æ®é›†ï¼Œåé¢æ˜¯å„ä¸ªæ–¹æ³•
            summary_headers = ['Dataset'] + factorization_list
            summary_table = PrettyTable(summary_headers)
            summary_table.align['Dataset'] = 'l'
            for header in summary_headers[1:]:
                summary_table.align[header] = 'r'
            
            # ä¸ºæ¯ä¸ªå™ªå£°å€¼ç”Ÿæˆä¸€ä¸ªè¡¨æ ¼
            for noise in noise_list:
                print(f'\n  Noise = {noise}')
                noise_table = PrettyTable(summary_headers)
                noise_table.align['Dataset'] = 'l'
                for header in summary_headers[1:]:
                    noise_table.align[header] = 'r'
                
                for dataset in dataset_list:
                    if dataset in all_results:
                        acc_key = 'neighbor' if use_neighbor else 'local'
                        if noise in all_results[dataset][acc_key]:
                            row = [dataset] + all_results[dataset][acc_key][noise]
                            noise_table.add_row(row)
                
                print(noise_table)
            
            # è®¡ç®—æ¯ä¸ªæ–¹æ³•çš„å¹³å‡å€¼ï¼ˆè·¨æ•°æ®é›†ï¼‰
            print(f'\n  {acc_type} Accuracy å¹³å‡å€¼ï¼ˆè·¨æ•°æ®é›†ï¼‰')
            avg_table = PrettyTable(summary_headers)
            avg_table.align['Dataset'] = 'l'
            for header in summary_headers[1:]:
                avg_table.align[header] = 'r'
            
            for noise in noise_list:
                # è®¡ç®—æ¯ä¸ªæ–¹æ³•åœ¨è¯¥å™ªå£°å€¼ä¸‹çš„å¹³å‡å€¼
                method_avgs = []
                for method_idx, method in enumerate(factorization_list):
                    method_values = []
                    for dataset in dataset_list:
                        if dataset in all_results:
                            acc_key = 'neighbor' if use_neighbor else 'local'
                            if noise in all_results[dataset][acc_key]:
                                val_str = all_results[dataset][acc_key][noise][method_idx]
                                val = extract_value(val_str)
                                if val > 0:
                                    method_values.append(val)
                    
                    if method_values:
                        avg_val = mean(method_values)
                        std_val = stdev(method_values) if len(method_values) > 1 else 0.0
                        method_avgs.append(f'{avg_val:.2f} Â± {std_val:.2f}')
                    else:
                        method_avgs.append('N/A')
                
                avg_table.add_row([f'Noise={noise}'] + method_avgs)
            
            print(avg_table)
        
        print("=" * 80)

def generate_exp4_mia_table(
    config_key: str = 'EXPERIMENT_4_MIA',
    config: Optional[Dict[str, Any]] = None,
    output_dir: Path = DEFAULT_OUTPUT_DIR,
    enable_postprocess: bool = True
) -> None:
    """
    ç”Ÿæˆå®éªŒ4ï¼ˆMIAæ”»å‡»ï¼‰çš„ç»“æœè¡¨æ ¼ï¼Œå±•ç¤ºæ¯ä¸ª label çš„æ”»å‡»æˆåŠŸç‡
    
    è¯»å–æ‰€æœ‰å®éªŒç»“æœæ–‡ä»¶ï¼ˆmia_acc_{noise}.pklï¼‰ï¼ŒæŒ‰æ•°æ®é›†å’Œå™ªå£°å€¼ç»„ç»‡æ•°æ®ï¼Œ
    ç”Ÿæˆè¡¨æ ¼å±•ç¤ºæ¯ä¸ª label åœ¨ä¸åŒ noise ä¸‹çš„æ”»å‡»æˆåŠŸç‡ã€‚
    
    æ–‡ä»¶è·¯å¾„ç»“æ„ï¼ˆä¸ mia.py ä¿æŒä¸€è‡´ï¼‰ï¼š
        {output_dir}/{exp_name}/{dataset}/mia_acc_{noise}.pkl
        ä¾‹å¦‚ï¼š~/code/sepfpl/outputs/exp4-mia/oxford_flowers/mia_acc_0.0.pkl
    
    Args:
        config_key: å®éªŒé…ç½®é”®å
        config: å®éªŒé…ç½®å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™ä» EXPERIMENT_CONFIGS è¯»å–
        output_dir: ç»“æœæ–‡ä»¶çš„åŸºç¡€ç›®å½•ï¼Œé»˜è®¤ä¸º ~/code/sepfpl/outputs
        enable_postprocess: æ˜¯å¦å¯ç”¨åå¤„ç†ï¼ˆå½“å‰æœªä½¿ç”¨ï¼Œä¿ç•™æ¥å£ä¸€è‡´æ€§ï¼‰
    """
    if config is None:
        if config_key not in EXPERIMENT_CONFIGS:
            print(f"âŒ é”™è¯¯: é…ç½®é”® '{config_key}' ä¸å­˜åœ¨")
            return
        config = EXPERIMENT_CONFIGS[config_key]
    
    exp_name = config.get('exp_name', 'exp4-mia')
    dataset_list = config.get('dataset_list', [])
    noise_list = config.get('noise_list', [])
    
    if not dataset_list:
        print(f"âŒ é”™è¯¯: é…ç½®ä¸­æœªæŒ‡å®šæ•°æ®é›†åˆ—è¡¨")
        return
    
    if not noise_list:
        print(f"âŒ é”™è¯¯: é…ç½®ä¸­æœªæŒ‡å®šå™ªå£°åˆ—è¡¨")
        return
    
    # æ„å»ºå®éªŒç›®å½•è·¯å¾„
    exp_dir = output_dir / exp_name
    
    if not exp_dir.exists():
        print(f"âŒ é”™è¯¯: å®éªŒç›®å½•ä¸å­˜åœ¨: {exp_dir}")
        return
    
    # è¯»å–æ‰€æœ‰ç»“æœ
    # results[dataset][noise] = {'average': float, 'per_label': {label: accuracy}}
    results = {}
    
    for dataset in dataset_list:
        dataset_dir = exp_dir / dataset
        if not dataset_dir.exists():
            print(f"âš ï¸  è­¦å‘Š: æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_dir}")
            continue
        
        results[dataset] = {}
        
        for noise in noise_list:
            # æ„å»ºæ–‡ä»¶è·¯å¾„
            mia_acc_file = dataset_dir / f'mia_acc_{noise}.pkl'
            if mia_acc_file.exists():
                try:
                    with open(mia_acc_file, 'rb') as f:
                        data = pickle.load(f)
                    
                    if isinstance(data, dict):
                        # æ–°æ ¼å¼ï¼ˆmia.py test_attack_modelsä¿å­˜çš„æ ¼å¼ï¼‰ï¼š
                        # åŒ…å« 'average', 'per_label', 'total_samples', 'correct_samples',
                        # 'per_label_samples', 'per_label_correct'
                        if 'per_label' in data and isinstance(data['per_label'], dict):
                            results[dataset][noise] = {
                                'average': data.get('average', 0.0),
                                'per_label': data['per_label'],
                                'total_samples': data.get('total_samples', 0),
                                'correct_samples': data.get('correct_samples', 0),
                                'per_label_samples': data.get('per_label_samples', {}),
                                'per_label_correct': data.get('per_label_correct', {})
                            }
                        elif 'average' in data:
                            # åªæœ‰å¹³å‡å€¼çš„æ—§æ ¼å¼
                            results[dataset][noise] = {
                                'average': data['average'],
                                'per_label': {},
                                'total_samples': data.get('total_samples', 0),
                                'correct_samples': data.get('correct_samples', 0),
                                'per_label_samples': {},
                                'per_label_correct': {}
                            }
                        else:
                            print(f"âš ï¸  è­¦å‘Š: {mia_acc_file} ä¸­çš„å­—å…¸æ ¼å¼ä¸æ­£ç¡®")
                            results[dataset][noise] = None
                    elif isinstance(data, (int, float)):
                        # æ—§æ ¼å¼ï¼šç›´æ¥æ˜¯ float ç±»å‹çš„å¹³å‡æ”»å‡»æˆåŠŸç‡
                        results[dataset][noise] = {
                            'average': float(data),
                            'per_label': {}
                        }
                    else:
                        print(f"âš ï¸  è­¦å‘Š: {mia_acc_file} ä¸­çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®: {type(data)}")
                        results[dataset][noise] = None
                except Exception as e:
                    print(f"âš ï¸  è­¦å‘Š: æ— æ³•è¯»å– {mia_acc_file}: {e}")
                    results[dataset][noise] = None
            else:
                results[dataset][noise] = None
    
    # ä¸ºæ¯ä¸ªæ•°æ®é›†ç”Ÿæˆè¡¨æ ¼
    for dataset in dataset_list:
        if dataset not in results:
            continue
        
        print("\n" + "=" * 100)
        print(f"ğŸ“Š å®éªŒ4 (MIAæ”»å‡») ç»“æœè¡¨æ ¼ - {exp_name} - {dataset}")
        print("=" * 100)
        
        # åˆ›å»ºè¡¨æ ¼
        table = PrettyTable()
        
        # è¡¨å¤´ï¼šç¬¬ä¸€åˆ—æ˜¯ Labelï¼Œåé¢æ˜¯å„ä¸ªå™ªå£°å€¼ï¼Œæœ€åä¸€åˆ—æ˜¯å¹³å‡å€¼
        headers = ['Label'] + [f'Noise={n:.2f}' for n in noise_list] + ['Average']
        table.field_names = headers
        
        # å¯¹é½æ–¹å¼
        table.align['Label'] = 'l'
        for header in headers[1:]:
            table.align[header] = 'r'
        
        # æ”¶é›†å½“å‰æ•°æ®é›†çš„æ‰€æœ‰ labelï¼ˆä»…è¯¥æ•°æ®é›†çš„ labelï¼Œä¸é‡å ï¼‰
        dataset_labels = set()
        for noise in noise_list:
            if dataset in results and results[dataset].get(noise) is not None:
                per_label = results[dataset][noise].get('per_label', {})
                dataset_labels.update(per_label.keys())
        
        # å¦‚æœæœ‰ per_label æ•°æ®ï¼ŒæŒ‰ label æ’åº
        if dataset_labels:
            def label_sort_key(x):
                """è¾…åŠ©å‡½æ•°ï¼šå°† label è½¬æ¢ä¸ºå¯æ¯”è¾ƒçš„å€¼ç”¨äºæ’åº"""
                if isinstance(x, int):
                    return (0, x)  # æ•´æ•°ä¼˜å…ˆ
                elif isinstance(x, str) and x.isdigit():
                    return (0, int(x))  # æ•°å­—å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•´æ•°
                else:
                    return (1, str(x))  # å…¶ä»–å­—ç¬¦ä¸²æ”¾åœ¨åé¢
            
            sorted_labels = sorted(dataset_labels, key=label_sort_key)
        else:
            sorted_labels = []
        
        # æ·»åŠ æ¯ä¸ª label çš„è¡Œ
        for label in sorted_labels:
            row = [f'Label {label}']
            label_accs = []
            
            for noise in noise_list:
                if dataset in results and results[dataset].get(noise) is not None:
                    per_label = results[dataset][noise].get('per_label', {})
                    if label in per_label:
                        acc = per_label[label]
                        row.append(f'{acc:.4f}')
                        label_accs.append(acc)
                    else:
                        row.append('N/A')
                else:
                    row.append('N/A')
            
            # è®¡ç®—è¯¥ label çš„å¹³å‡å€¼
            if label_accs:
                label_avg = sum(label_accs) / len(label_accs)
                row.append(f'{label_avg:.4f}')
            else:
                row.append('N/A')
            
            table.add_row(row)
        
        # æ·»åŠ å¹³å‡æ”»å‡»æˆåŠŸç‡è¡Œ
        avg_row = ['Average']
        avg_accs = []
        
        for noise in noise_list:
            if dataset in results and results[dataset].get(noise) is not None:
                avg_acc = results[dataset][noise].get('average', 0.0)
                avg_row.append(f'{avg_acc:.4f}')
                avg_accs.append(avg_acc)
            else:
                avg_row.append('N/A')
        
        # æœ€åä¸€åˆ—çš„å¹³å‡å€¼ï¼ˆæ‰€æœ‰ noise çš„å¹³å‡ï¼‰
        if avg_accs:
            overall_avg = sum(avg_accs) / len(avg_accs)
            avg_row.append(f'{overall_avg:.4f}')
        else:
            avg_row.append('N/A')
        
        table.add_row(avg_row)
        
        # è¾“å‡ºè¡¨æ ¼
        print(table)
        print("=" * 100)
        
        # ä¿å­˜è¡¨æ ¼åˆ°æ–‡ä»¶
        output_file = exp_dir / dataset / 'mia_results_per_label.txt'
        output_file.parent.mkdir(parents=True, exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("=" * 100 + "\n")
            f.write(f"å®éªŒ4 (MIAæ”»å‡») ç»“æœè¡¨æ ¼ - {exp_name} - {dataset}\n")
            f.write("=" * 100 + "\n")
            f.write(str(table))
            f.write("\n" + "=" * 100 + "\n")
        
        print(f"\nğŸ’¾ è¡¨æ ¼å·²ä¿å­˜åˆ°: {output_file}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœ
        has_results = any(
            results.get(dataset, {}).get(noise) is not None
            for noise in noise_list
        )
        if not has_results:
            print(f"\nâš ï¸  è­¦å‘Š: æ•°æ®é›† {dataset} æœªæ‰¾åˆ°ä»»ä½•å®éªŒç»“æœ")
    
    print("\n" + "=" * 100)


def read_data_with_sepfpl_params(exp_name: str, dataset: str, factorization: str, rank: int,
                                  noise: float, seed_list: List[int], num_users: Optional[int],
                                  sepfpl_topk: int, rdp_p: float,
                                  output_base_dir: Path, tail_epochs: int, 
                                  skip_exp_name: bool = False) -> Tuple[str, str]:
    """
    è¯»å–åŒ…å« sepfpl_topk å’Œ rdp_p å‚æ•°çš„å•ç‚¹æ•°æ®ï¼ˆç”¨äºå®éªŒ1ï¼šStandardå’ŒExtensionï¼‰
    
    æ–‡ä»¶åæ ¼å¼ï¼šacc_sepfpl_{rank}_{noise}_{seed}_{topk}_{rdp_p}_{num_users}.pkl
    ä¾‹å¦‚ï¼šacc_sepfpl_8_0.4_1_4_0.8_10.pkl
    
    å‚æ•°:
        skip_exp_name: å¦‚æœä¸º Trueï¼Œè·³è¿‡ exp_name è¿™ä¸€å±‚ç›®å½•ï¼ˆç”¨äºå®éªŒä¸‰ï¼‰
    """
    per_seed_local, per_seed_neighbor = [], []
    if skip_exp_name:
        base_dir = output_base_dir / dataset
    else:
        base_dir = output_base_dir / exp_name / dataset

    for seed in seed_list:
        # ç¡®ä¿ noise æ ¼å¼åŒ–ä¸ºæµ®ç‚¹æ•°å­—ç¬¦ä¸²
        if noise == int(noise):
            noise_str = f'{float(noise):.1f}'
        else:
            noise_str = f'{float(noise):g}'
        
        # rdp_p ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²å½¢å¼ï¼Œä¿ç•™åŸå§‹æ ¼å¼ï¼ˆåŒ…å«ç‚¹å·ï¼‰
        rdp_p_str = str(rdp_p)
        
        # æ„å»ºæ–‡ä»¶åæ¨¡å¼ï¼šacc_sepfpl_{rank}_{noise}_{seed}_{topk}_{rdp_p}_{num_users}
        pattern = f'acc_{factorization}_{rank}_{noise_str}_{seed}_{sepfpl_topk}_{rdp_p_str}_{num_users}'
        
        file_path = base_dir / f'{pattern}.pkl'
        if not file_path.exists():
            # å°è¯•ä½¿ç”¨ glob æ¨¡å¼åŒ¹é…ï¼ˆä»¥é˜²æ–‡ä»¶åæ ¼å¼ç•¥æœ‰ä¸åŒï¼‰
            glob_pattern = f'acc_{factorization}_{rank}_{noise_str}_{seed}_*_{num_users}.pkl'
            matches = list(base_dir.glob(glob_pattern))
            # ä»åŒ¹é…çš„æ–‡ä»¶ä¸­ç­›é€‰å‡º topk å’Œ rdp_p éƒ½åŒ¹é…çš„æ–‡ä»¶
            for match in matches:
                # ä»æ–‡ä»¶åä¸­æå– topk å’Œ rdp_p å€¼
                # æ–‡ä»¶åæ ¼å¼ï¼šacc_sepfpl_{rank}_{noise}_{seed}_{topk}_{rdp_p}_{num_users}.pkl
                # æ‹†åˆ†åï¼š["acc", "sepfpl", "8", "0.4", "1", "4", "0.8", "10"]
                parts = match.stem.split('_')
                if len(parts) >= 8:
                    # parts[0]="acc", parts[1]="sepfpl", parts[2]=rank, parts[3]=noise, 
                    # parts[4]=seed, parts[5]=topk, parts[6]=rdp_p, parts[7]=num_users
                    try:
                        # å°è¯•è§£æ topk å’Œ rdp_p
                        file_topk = int(parts[5])
                        file_rdp_p = float(parts[6])
                        if file_topk == sepfpl_topk and abs(file_rdp_p - rdp_p) < 1e-6:
                            file_path = match
                            break
                    except (ValueError, IndexError):
                        continue
            else:
                # å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶ï¼Œè·³è¿‡
                continue
        
        l_hist, n_hist = load_metrics(file_path)
        if l_hist: per_seed_local.extend(tail_values(l_hist, tail_epochs))
        if n_hist: per_seed_neighbor.extend(tail_values(n_hist, tail_epochs))
    
    return format_stats(per_seed_local), format_stats(per_seed_neighbor)


def generate_exp1_table(
    config_key: str,
    config: Optional[Dict[str, Any]] = None,
    output_dir: Path = DEFAULT_OUTPUT_DIR,
    tail_epochs: int = DEFAULT_TAIL_EPOCHS,
    enable_postprocess: bool = True
) -> None:
    """
    ç”Ÿæˆå®éªŒ1 (Standard å’Œ Extension) çš„ç»“æœè¡¨æ ¼
    
    å®éªŒç‰¹ç‚¹ï¼š
    - EXPERIMENT_1_STANDARD: å¤šä¸ªæ•°æ®é›†ï¼Œå›ºå®š10ä¸ªç”¨æˆ·ï¼Œå¤šä¸ªnoiseå€¼
    - EXPERIMENT_1_EXTENSION: cifar-100æ•°æ®é›†ï¼Œ25å’Œ50ä¸ªç”¨æˆ·ï¼Œå¤šä¸ªnoiseå€¼
    - å›ºå®š rank=8, sepfpl_topk=4, rdp_p=0.8
    - sepfplæ–¹æ³•
    
    è¡¨æ ¼æ ¼å¼ï¼š
    - STANDARD: æ¯ä¸ªæ•°æ®é›†ä¸€ä¸ªè¡¨æ ¼ï¼Œè¡Œ=noiseï¼Œåˆ—=æ–¹æ³•ï¼ˆé€šå¸¸åªæœ‰ä¸€ä¸ªsepfplï¼‰
    - EXTENSION: æ¯ä¸ªç”¨æˆ·æ•°ä¸€ä¸ªè¡¨æ ¼ï¼Œè¡Œ=noiseï¼Œåˆ—=æ–¹æ³•
    """
    # è·å–é…ç½®
    if config is None:
        if config_key not in EXPERIMENT_CONFIGS:
            print(f"âŒ é”™è¯¯: é…ç½®é”® '{config_key}' ä¸å­˜åœ¨")
            return
        config = EXPERIMENT_CONFIGS[config_key]
    
    exp_name = config.get('exp_name', 'exp1')
    dataset_list = config.get('dataset_list', [])
    factorization_list = config.get('factorization_list', ['sepfpl'])
    noise_list = config.get('noise_list', [0.0, 0.4, 0.2, 0.1, 0.05, 0.01])
    seed_list = config.get('seed_list', [1])
    rank_list = config.get('rank_list', [8])
    num_users_list = config.get('num_users_list', [config.get('num_users', 10)])
    sepfpl_topk = config.get('sepfpl_topk', 4)
    rdp_p = config.get('rdp_p', 0.8)
    
    exp_type = 'exp1'
    postprocess_status = "å¯ç”¨" if enable_postprocess else "ç¦ç”¨"
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š å®éªŒ1 - {exp_name}")
    print(f"   é…ç½®é”®: {config_key} | åå¤„ç†: {postprocess_status}")
    print(f"{'='*80}")
    
    rank = rank_list[0] if rank_list else 8
    
    # ä¸ºæ¯ä¸ªæ•°æ®é›†ç”Ÿæˆè¡¨æ ¼
    for dataset in dataset_list:
        for num_users in num_users_list:
            header_info = f"Dataset: {dataset}"
            if len(num_users_list) > 1:
                header_info += f" | Users: {num_users}"
            print(f"\n{'='*60}")
            print(f">>> {header_info} (Rank={rank}, TopK={sepfpl_topk}, rdp_p={rdp_p})")
            print(f"{'='*60}")
            
            # æ„å»ºè¡¨å¤´
            headers = ['Noise'] + factorization_list
            t_local = PrettyTable(headers)
            t_neighbor = PrettyTable(headers)
            t_local.align['Noise'] = 'l'
            t_neighbor.align['Noise'] = 'l'
            for header in headers[1:]:
                t_local.align[header] = 'r'
                t_neighbor.align[header] = 'r'
            
            for noise in noise_list:
                # å¯¹äº sepfpl æ–¹æ³•ï¼Œä½¿ç”¨æ–°çš„è¯»å–å‡½æ•°
                l_list, n_list = [], []
                for factorization in factorization_list:
                    if factorization in ['sepfpl', 'sepfpl_time_adaptive', 'sepfpl_hcse']:
                        # ä½¿ç”¨åŒ…å« topk å’Œ rdp_p çš„è¯»å–å‡½æ•°
                        l_stat, n_stat = read_data_with_sepfpl_params(
                            exp_name, dataset, factorization, rank, noise,
                            seed_list, num_users, sepfpl_topk, rdp_p,
                            output_dir, tail_epochs
                        )
                    else:
                        # å¯¹äºé sepfpl æ–¹æ³•ï¼Œä½¿ç”¨åŸæœ‰çš„è¯»å–å‡½æ•°
                        l_stat, n_stat = read_data(
                            exp_name, dataset, factorization, rank, noise,
                            seed_list, num_users, output_dir, tail_epochs
                        )
                    l_list.append(l_stat)
                    n_list.append(n_stat)
                
                if enable_postprocess:
                    l_proc = postprocess_results(l_list, factorization_list, exp_type)
                    n_proc = postprocess_results(n_list, factorization_list, exp_type)
                else:
                    l_proc = l_list
                    n_proc = n_list
                
                t_local.add_row([noise] + l_proc)
                t_neighbor.add_row([noise] + n_proc)
            
            print(f'\nğŸ“Š [Local Accuracy] (Rank={rank})')
            print(t_local)
            print(f'\nğŸ“Š [Neighbor Accuracy] (Rank={rank})')
            print(t_neighbor)
            
            print("-" * 60)


def read_data_with_rdp_p(exp_name: str, dataset: str, factorization: str, rank: int, 
                         noise: float, seed_list: List[int], num_users: Optional[int],
                         sepfpl_topk: int, rdp_p: float,
                         output_base_dir: Path, tail_epochs: int,
                         skip_exp_name: bool = False) -> Tuple[str, str]:
    """
    è¯»å–åŒ…å« rdp_p å‚æ•°çš„å•ç‚¹æ•°æ®ï¼ˆç”¨äºå®éªŒ3.3ï¼šrdp_pæ•æ„Ÿæ€§åˆ†æï¼‰
    
    æ–‡ä»¶åæ ¼å¼ï¼šacc_sepfpl_{rank}_{noise}_{seed}_{topk}_{rdp_p}_{num_users}.pkl
    ä¾‹å¦‚ï¼šacc_sepfpl_8_0.4_1_8_1.1_10.pkl
    
    å‚æ•°:
        skip_exp_name: å¦‚æœä¸º Trueï¼Œè·³è¿‡ exp_name è¿™ä¸€å±‚ç›®å½•ï¼ˆç”¨äºå®éªŒä¸‰ï¼‰
    """
    per_seed_local, per_seed_neighbor = [], []
    if skip_exp_name:
        base_dir = output_base_dir / dataset
    else:
        base_dir = output_base_dir / exp_name / dataset

    for seed in seed_list:
        # ç¡®ä¿ noise æ ¼å¼åŒ–ä¸ºæµ®ç‚¹æ•°å­—ç¬¦ä¸²
        if noise == int(noise):
            noise_str = f'{float(noise):.1f}'
        else:
            noise_str = f'{float(noise):g}'
        
        # rdp_p ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²å½¢å¼ï¼Œä¿ç•™åŸå§‹æ ¼å¼ï¼ˆåŒ…å«ç‚¹å·ï¼‰
        # ä¾‹å¦‚ï¼š0 -> "0", 0.1 -> "0.1", 1.1 -> "1.1"
        rdp_p_str = str(rdp_p)
        
        # æ„å»ºæ–‡ä»¶åæ¨¡å¼ï¼šacc_sepfpl_{rank}_{noise}_{seed}_{topk}_{rdp_p}_{num_users}
        pattern = f'acc_{factorization}_{rank}_{noise_str}_{seed}_{sepfpl_topk}_{rdp_p_str}_{num_users}'
        
        file_path = base_dir / f'{pattern}.pkl'
        if not file_path.exists():
            # å°è¯•ä½¿ç”¨ glob æ¨¡å¼åŒ¹é…ï¼ˆä»¥é˜²æ–‡ä»¶åæ ¼å¼ç•¥æœ‰ä¸åŒï¼‰
            # æ³¨æ„ï¼šrdp_p å¯èƒ½åŒ…å«ç‚¹å·ï¼Œéœ€è¦è½¬ä¹‰æˆ–ä½¿ç”¨é€šé…ç¬¦
            glob_pattern = f'acc_{factorization}_{rank}_{noise_str}_{seed}_{sepfpl_topk}_*_{num_users}.pkl'
            matches = list(base_dir.glob(glob_pattern))
            # ä»åŒ¹é…çš„æ–‡ä»¶ä¸­ç­›é€‰å‡º rdp_p åŒ¹é…çš„æ–‡ä»¶
            for match in matches:
                # ä»æ–‡ä»¶åä¸­æå– rdp_p å€¼
                # æ–‡ä»¶åæ ¼å¼ï¼šacc_sepfpl_{rank}_{noise}_{seed}_{topk}_{rdp_p}_{num_users}.pkl
                # æ‹†åˆ†åï¼š["acc", "sepfpl", "8", "0.4", "1", "8", "1.1", "10"]
                parts = match.stem.split('_')
                if len(parts) >= 8:
                    # æ‰¾åˆ° rdp_p çš„ä½ç½®ï¼ˆåœ¨ topk ä¹‹åï¼Œnum_users ä¹‹å‰ï¼‰
                    # parts[0]="acc", parts[1]="sepfpl", parts[2]=rank, parts[3]=noise, 
                    # parts[4]=seed, parts[5]=topk, parts[6]=rdp_p, parts[7]=num_users
                    try:
                        # å°è¯•è§£æ rdp_pï¼ˆå¯èƒ½æ˜¯ "0", "0.1", "1.1" ç­‰ï¼‰
                        file_rdp_p = float(parts[6])  # parts[6] åº”è¯¥æ˜¯ rdp_p
                        if abs(file_rdp_p - rdp_p) < 1e-6:  # æµ®ç‚¹æ•°æ¯”è¾ƒ
                            file_path = match
                            break
                    except (ValueError, IndexError):
                        continue
            else:
                # å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶ï¼Œè·³è¿‡
                continue
        
        l_hist, n_hist = load_metrics(file_path)
        if l_hist: per_seed_local.extend(tail_values(l_hist, tail_epochs))
        if n_hist: per_seed_neighbor.extend(tail_values(n_hist, tail_epochs))
    
    return format_stats(per_seed_local), format_stats(per_seed_neighbor)


def read_data_with_topk(exp_name: str, dataset: str, factorization: str, rank: int, 
                        noise: float, seed_list: List[int], num_users: Optional[int],
                        sepfpl_topk: int, rdp_p: float,
                        output_base_dir: Path, tail_epochs: int,
                        skip_exp_name: bool = False) -> Tuple[str, str]:
    """
    è¯»å–åŒ…å« sepfpl_topk å‚æ•°çš„å•ç‚¹æ•°æ®ï¼ˆç”¨äºå®éªŒ3.2ï¼šsepfpl_topkæ•æ„Ÿæ€§åˆ†æï¼‰
    
    æ–‡ä»¶åæ ¼å¼ï¼šacc_sepfpl_{rank}_{noise}_{seed}_{topk}_{rdp_p}_{num_users}.pkl
    ä¾‹å¦‚ï¼šacc_sepfpl_8_0.4_1_8_0.8_10.pkl
    
    å‚æ•°:
        skip_exp_name: å¦‚æœä¸º Trueï¼Œè·³è¿‡ exp_name è¿™ä¸€å±‚ç›®å½•ï¼ˆç”¨äºå®éªŒä¸‰ï¼‰
    """
    per_seed_local, per_seed_neighbor = [], []
    if skip_exp_name:
        base_dir = output_base_dir / dataset
    else:
        base_dir = output_base_dir / exp_name / dataset

    for seed in seed_list:
        # ç¡®ä¿ noise æ ¼å¼åŒ–ä¸ºæµ®ç‚¹æ•°å­—ç¬¦ä¸²
        if noise == int(noise):
            noise_str = f'{float(noise):.1f}'
        else:
            noise_str = f'{float(noise):g}'
        
        # rdp_p ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²å½¢å¼ï¼Œä¿ç•™åŸå§‹æ ¼å¼ï¼ˆåŒ…å«ç‚¹å·ï¼‰
        rdp_p_str = str(rdp_p)
        
        # æ„å»ºæ–‡ä»¶åæ¨¡å¼ï¼šacc_sepfpl_{rank}_{noise}_{seed}_{topk}_{rdp_p}_{num_users}
        pattern = f'acc_{factorization}_{rank}_{noise_str}_{seed}_{sepfpl_topk}_{rdp_p_str}_{num_users}'
        
        file_path = base_dir / f'{pattern}.pkl'
        if not file_path.exists():
            # å°è¯•ä½¿ç”¨ glob æ¨¡å¼åŒ¹é…ï¼ˆä»¥é˜²æ–‡ä»¶åæ ¼å¼ç•¥æœ‰ä¸åŒï¼‰
            glob_pattern = f'acc_{factorization}_{rank}_{noise_str}_{seed}_*_{rdp_p_str}_{num_users}.pkl'
            matches = list(base_dir.glob(glob_pattern))
            # ä»åŒ¹é…çš„æ–‡ä»¶ä¸­ç­›é€‰å‡º topk åŒ¹é…çš„æ–‡ä»¶
            for match in matches:
                # ä»æ–‡ä»¶åä¸­æå– topk å€¼
                # æ–‡ä»¶åæ ¼å¼ï¼šacc_sepfpl_{rank}_{noise}_{seed}_{topk}_{rdp_p}_{num_users}.pkl
                # æ‹†åˆ†åï¼š["acc", "sepfpl", "8", "0.4", "1", "8", "0.8", "10"]
                parts = match.stem.split('_')
                if len(parts) >= 8:
                    # æ‰¾åˆ° topk çš„ä½ç½®ï¼ˆåœ¨ seed ä¹‹åï¼Œrdp_p ä¹‹å‰ï¼‰
                    # parts[0]="acc", parts[1]="sepfpl", parts[2]=rank, parts[3]=noise, 
                    # parts[4]=seed, parts[5]=topk, parts[6]=rdp_p, parts[7]=num_users
                    try:
                        # å°è¯•è§£æ topkï¼ˆåº”è¯¥æ˜¯æ•´æ•°ï¼‰
                        file_topk = int(parts[5])  # parts[5] åº”è¯¥æ˜¯ topk
                        if file_topk == sepfpl_topk:
                            file_path = match
                            break
                    except (ValueError, IndexError):
                        continue
            else:
                # å¦‚æœæ²¡æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶ï¼Œè·³è¿‡
                continue
        
        l_hist, n_hist = load_metrics(file_path)
        if l_hist: per_seed_local.extend(tail_values(l_hist, tail_epochs))
        if n_hist: per_seed_neighbor.extend(tail_values(n_hist, tail_epochs))
    
    return format_stats(per_seed_local), format_stats(per_seed_neighbor)


def generate_exp3_rank_table(
    config_key: str = 'EXPERIMENT_3_Sensitivity_Analysis_rank',
    config: Optional[Dict[str, Any]] = None,
    output_dir: Path = DEFAULT_OUTPUT_DIR,
    tail_epochs: int = DEFAULT_TAIL_EPOCHS,
    enable_postprocess: bool = False
) -> None:
    """
    ç”Ÿæˆå®éªŒ3.1 (rankæ•æ„Ÿæ€§åˆ†æ) çš„ç»“æœè¡¨æ ¼
    
    å®éªŒç‰¹ç‚¹ï¼š
    - å›ºå®š sepfpl_topk=4, rdp_p=0.8
    - å˜åŒ– rank å€¼ï¼š[1, 2, 4, 8, 16]
    - å˜åŒ– noise å€¼ï¼š[0, 0.4, 0.1, 0.01]
    
    è¡¨æ ¼æ ¼å¼ï¼š
    - è¡Œï¼šnoise å€¼
    - åˆ—ï¼šrank å€¼
    - æ¯ä¸ªå•å…ƒæ ¼æ˜¾ç¤º Local å’Œ Neighbor çš„å‡†ç¡®ç‡
    """
    # è·å–é…ç½®
    if config is None:
        if config_key not in EXPERIMENT_CONFIGS:
            print(f"âŒ é”™è¯¯: é…ç½®é”® '{config_key}' ä¸å­˜åœ¨")
            return
        config = EXPERIMENT_CONFIGS[config_key]
    
    exp_name = config.get('exp_name', 'exp3-sensitivity-analysis-rank')
    dataset_list = config.get('dataset_list', [])
    factorization_list = config.get('factorization_list', ['sepfpl'])
    noise_list = config.get('noise_list', [0, 0.4, 0.1, 0.01])
    seed_list = config.get('seed_list', [1])
    rank_list = config.get('rank_list', [1, 2, 4, 8, 16])
    num_users_list = config.get('num_users_list', [config.get('num_users', 10)])
    sepfpl_topk = config.get('sepfpl_topk', 8)  # æ›´æ–°é»˜è®¤å€¼ä»¥åŒ¹é…é…ç½®
    rdp_p = config.get('rdp_p', 0.2)  # æ›´æ–°é»˜è®¤å€¼ä»¥åŒ¹é…é…ç½®
    
    postprocess_status = "å¯ç”¨" if enable_postprocess else "ç¦ç”¨"
    
    # å®éªŒä¸‰çš„æ•°æ®ä¿å­˜åœ¨ outputs/exp3 ç›®å½•ä¸‹
    exp3_output_dir = output_dir / 'exp3'
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š å®éªŒ3.1 (rankæ•æ„Ÿæ€§åˆ†æ) - {exp_name}")
    print(f"   é…ç½®é”®: {config_key} | åå¤„ç†: {postprocess_status}")
    print(f"   æ•°æ®ç›®å½•: {exp3_output_dir}")
    print(f"{'='*80}")
    
    # ä¸ºæ¯ä¸ªæ•°æ®é›†ç”Ÿæˆè¡¨æ ¼
    for dataset in dataset_list:
        for num_users in num_users_list:
            header_info = f"Dataset: {dataset}"
            if len(num_users_list) > 1:
                header_info += f" | Users: {num_users}"
            print(f"\n{'='*60}")
            print(f">>> {header_info} (TopK={sepfpl_topk}, rdp_p={rdp_p})")
            print(f"{'='*60}")
            
            # åˆ†åˆ«ç”Ÿæˆ Local å’Œ Neighbor è¡¨æ ¼
            for acc_type, use_neighbor in [('Local', False), ('Neighbor', True)]:
                print(f'\nğŸ“Š {acc_type} Accuracy ({dataset})')
                
                # æ„å»ºè¡¨å¤´ï¼šç¬¬ä¸€åˆ—æ˜¯ Noiseï¼Œåé¢æ˜¯å„ä¸ª rank å€¼
                headers = ['Noise'] + [f'rank={rank}' if rank != 16 else 'rank=16 (Full)' for rank in rank_list]
                table = PrettyTable(headers)
                table.align['Noise'] = 'l'
                for header in headers[1:]:
                    table.align[header] = 'r'
                
                # ä¸ºæ¯ä¸ª noise å€¼æ„å»ºä¸€è¡Œ
                for noise in noise_list:
                    row = [noise]
                    
                    # ä¸ºæ¯ä¸ª rank å€¼è¯»å–æ•°æ®
                    for rank in rank_list:
                        l_stat, n_stat = read_data_with_sepfpl_params(
                            exp_name, dataset, factorization_list[0], rank, noise,
                            seed_list, num_users, sepfpl_topk, rdp_p,
                            exp3_output_dir, tail_epochs, skip_exp_name=True
                        )
                        
                        # é€‰æ‹© Local æˆ– Neighbor
                        stat = n_stat if use_neighbor else l_stat
                        row.append(stat)
                    
                    table.add_row(row)
                
                print(table)
            
            print("-" * 60)


def generate_exp3_topk_table(
    config_key: str = 'EXPERIMENT_3_Sensitivity_Analysis_sepfpl_topk',
    config: Optional[Dict[str, Any]] = None,
    output_dir: Path = DEFAULT_OUTPUT_DIR,
    tail_epochs: int = DEFAULT_TAIL_EPOCHS,
    enable_postprocess: bool = False
) -> None:
    """
    ç”Ÿæˆå®éªŒ3.2 (sepfpl_topkæ•æ„Ÿæ€§åˆ†æ) çš„ç»“æœè¡¨æ ¼
    
    å®éªŒç‰¹ç‚¹ï¼š
    - å›ºå®š rank=8, rdp_p=0.8
    - å˜åŒ– sepfpl_topk å€¼ï¼š[2, 4, 6, 8]
    - å˜åŒ– noise å€¼ï¼š[0.4, 0.1, 0.01]
    
    è¡¨æ ¼æ ¼å¼ï¼š
    - è¡Œï¼šnoise å€¼
    - åˆ—ï¼šsepfpl_topk å€¼
    - æ¯ä¸ªå•å…ƒæ ¼æ˜¾ç¤º Local å’Œ Neighbor çš„å‡†ç¡®ç‡
    """
    # è·å–é…ç½®
    if config is None:
        if config_key not in EXPERIMENT_CONFIGS:
            print(f"âŒ é”™è¯¯: é…ç½®é”® '{config_key}' ä¸å­˜åœ¨")
            return
        config = EXPERIMENT_CONFIGS[config_key]
    
    exp_name = config.get('exp_name', 'exp3-sensitivity-analysis-sepfpl-topk')
    dataset_list = config.get('dataset_list', [])
    factorization_list = config.get('factorization_list', ['sepfpl'])
    noise_list = config.get('noise_list', [0, 0.4, 0.1, 0.01])  # æ›´æ–°é»˜è®¤å€¼ä»¥åŒ¹é…é…ç½®
    seed_list = config.get('seed_list', [1])
    rank_list = config.get('rank_list', [8])
    num_users_list = config.get('num_users_list', [config.get('num_users', 10)])
    sepfpl_topk_list = config.get('sepfpl_topk_list', [2, 4, 6, 8])
    rdp_p = config.get('rdp_p', 0.2)  # æ›´æ–°é»˜è®¤å€¼ä»¥åŒ¹é…é…ç½®
    
    postprocess_status = "å¯ç”¨" if enable_postprocess else "ç¦ç”¨"
    
    # å®éªŒä¸‰çš„æ•°æ®ä¿å­˜åœ¨ outputs/exp3 ç›®å½•ä¸‹
    exp3_output_dir = output_dir / 'exp3'
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š å®éªŒ3.2 (sepfpl_topkæ•æ„Ÿæ€§åˆ†æ) - {exp_name}")
    print(f"   é…ç½®é”®: {config_key} | åå¤„ç†: {postprocess_status}")
    print(f"   æ•°æ®ç›®å½•: {exp3_output_dir}")
    print(f"{'='*80}")
    
    rank = rank_list[0] if rank_list else 8
    
    # ä¸ºæ¯ä¸ªæ•°æ®é›†ç”Ÿæˆè¡¨æ ¼
    for dataset in dataset_list:
        for num_users in num_users_list:
            header_info = f"Dataset: {dataset}"
            if len(num_users_list) > 1:
                header_info += f" | Users: {num_users}"
            print(f"\n{'='*60}")
            print(f">>> {header_info} (Rank={rank}, rdp_p={rdp_p})")
            print(f"{'='*60}")
            
            # åˆ†åˆ«ç”Ÿæˆ Local å’Œ Neighbor è¡¨æ ¼
            for acc_type, use_neighbor in [('Local', False), ('Neighbor', True)]:
                print(f'\nğŸ“Š {acc_type} Accuracy ({dataset})')
                
                # æ„å»ºè¡¨å¤´ï¼šç¬¬ä¸€åˆ—æ˜¯ Noiseï¼Œåé¢æ˜¯å„ä¸ª topk å€¼
                headers = ['Noise'] + [f'topk={topk}' for topk in sepfpl_topk_list]
                table = PrettyTable(headers)
                table.align['Noise'] = 'l'
                for header in headers[1:]:
                    table.align[header] = 'r'
                
                # ä¸ºæ¯ä¸ª noise å€¼æ„å»ºä¸€è¡Œ
                for noise in noise_list:
                    row = [noise]
                    
                    # ä¸ºæ¯ä¸ª topk å€¼è¯»å–æ•°æ®
                    for topk in sepfpl_topk_list:
                        l_stat, n_stat = read_data_with_topk(
                            exp_name, dataset, factorization_list[0], rank, noise,
                            seed_list, num_users, topk, rdp_p,
                            exp3_output_dir, tail_epochs, skip_exp_name=True
                        )
                        
                        # é€‰æ‹© Local æˆ– Neighbor
                        stat = n_stat if use_neighbor else l_stat
                        row.append(stat)
                    
                    table.add_row(row)
                
                print(table)
            
            print("-" * 60)


def generate_exp3_rdp_p_table(
    config_key: str = 'EXPERIMENT_3_Sensitivity_Analysis_rdp_p',
    config: Optional[Dict[str, Any]] = None,
    output_dir: Path = DEFAULT_OUTPUT_DIR,
    tail_epochs: int = DEFAULT_TAIL_EPOCHS,
    enable_postprocess: bool = False
) -> None:
    """
    ç”Ÿæˆå®éªŒ3.3 (rdp_pæ•æ„Ÿæ€§åˆ†æ) çš„ç»“æœè¡¨æ ¼
    
    å®éªŒç‰¹ç‚¹ï¼š
    - å›ºå®š rank=8, sepfpl_topk=8
    - å˜åŒ– rdp_p å€¼ï¼š[0, 0.1, 0.2, 0.4, 0.8]
    - å˜åŒ– noise å€¼ï¼š[0.4, 0.1, 0.01]
    
    è¡¨æ ¼æ ¼å¼ï¼š
    - è¡Œï¼šnoise å€¼
    - åˆ—ï¼šrdp_p å€¼
    - æ¯ä¸ªå•å…ƒæ ¼æ˜¾ç¤º Local å’Œ Neighbor çš„å‡†ç¡®ç‡
    """
    # è·å–é…ç½®
    if config is None:
        if config_key not in EXPERIMENT_CONFIGS:
            print(f"âŒ é”™è¯¯: é…ç½®é”® '{config_key}' ä¸å­˜åœ¨")
            return
        config = EXPERIMENT_CONFIGS[config_key]
    
    exp_name = config.get('exp_name', 'exp3-sensitivity-analysis-rdp-p')
    dataset_list = config.get('dataset_list', [])
    factorization_list = config.get('factorization_list', ['sepfpl'])
    noise_list = config.get('noise_list', [0.4, 0.1, 0.01])
    seed_list = config.get('seed_list', [1])
    rank_list = config.get('rank_list', [8])
    num_users_list = config.get('num_users_list', [config.get('num_users', 10)])
    sepfpl_topk = config.get('sepfpl_topk', 8)
    rdp_p_list = config.get('rdp_p_list', [0, 0.2, 0.5, 1])  # æ›´æ–°é»˜è®¤å€¼ä»¥åŒ¹é…é…ç½®
    
    postprocess_status = "å¯ç”¨" if enable_postprocess else "ç¦ç”¨"
    
    # å®éªŒä¸‰çš„æ•°æ®ä¿å­˜åœ¨ outputs/exp3 ç›®å½•ä¸‹
    exp3_output_dir = output_dir / 'exp3'
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š å®éªŒ3.3 (rdp_pæ•æ„Ÿæ€§åˆ†æ) - {exp_name}")
    print(f"   é…ç½®é”®: {config_key} | åå¤„ç†: {postprocess_status}")
    print(f"   æ•°æ®ç›®å½•: {exp3_output_dir}")
    print(f"{'='*80}")
    
    rank = rank_list[0] if rank_list else 8
    
    # ä¸ºæ¯ä¸ªæ•°æ®é›†ç”Ÿæˆè¡¨æ ¼
    for dataset in dataset_list:
        for num_users in num_users_list:
            header_info = f"Dataset: {dataset}"
            if len(num_users_list) > 1:
                header_info += f" | Users: {num_users}"
            print(f"\n{'='*60}")
            print(f">>> {header_info} (Rank={rank}, TopK={sepfpl_topk})")
            print(f"{'='*60}")
            
            # åˆ†åˆ«ç”Ÿæˆ Local å’Œ Neighbor è¡¨æ ¼
            for acc_type, use_neighbor in [('Local', False), ('Neighbor', True)]:
                print(f'\nğŸ“Š {acc_type} Accuracy ({dataset})')
                
                # æ„å»ºè¡¨å¤´ï¼šç¬¬ä¸€åˆ—æ˜¯ Noiseï¼Œåé¢æ˜¯å„ä¸ª rdp_p å€¼
                headers = ['Noise'] + [f'rdp_p={rdp_p}' for rdp_p in rdp_p_list]
                table = PrettyTable(headers)
                table.align['Noise'] = 'l'
                for header in headers[1:]:
                    table.align[header] = 'r'
                
                # ä¸ºæ¯ä¸ª noise å€¼æ„å»ºä¸€è¡Œ
                for noise in noise_list:
                    row = [noise]
                    
                    # ä¸ºæ¯ä¸ª rdp_p å€¼è¯»å–æ•°æ®
                    for rdp_p in rdp_p_list:
                        l_stat, n_stat = read_data_with_rdp_p(
                            exp_name, dataset, factorization_list[0], rank, noise,
                            seed_list, num_users, sepfpl_topk, rdp_p,
                            exp3_output_dir, tail_epochs, skip_exp_name=True
                        )
                        
                        # é€‰æ‹© Local æˆ– Neighbor
                        stat = n_stat if use_neighbor else l_stat
                        row.append(stat)
                    
                    table.add_row(row)
                
                print(table)
            
            print("-" * 60)


def main():
    parser = argparse.ArgumentParser(description="SepFPL å®éªŒç»“æœç”Ÿæˆå·¥å…·", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    
    exp_group = parser.add_argument_group("å®éªŒé…ç½®")
    for arg_name, (_, desc) in EXP_ARG_MAP.items():
        exp_group.add_argument(f"--{arg_name.replace('_', '-')}", action="store_true", help=desc)

    parser.add_argument("--output-dir", type=Path, default=DEFAULT_OUTPUT_DIR, help="æ•°æ®ç›®å½•")
    parser.add_argument("--tail-epochs", type=int, default=DEFAULT_TAIL_EPOCHS, help="ç»Ÿè®¡è½®æ¬¡")
    parser.add_argument("--output-file", type=Path, default=None, 
                       help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆåŒæ—¶è¾“å‡ºåˆ°ç»ˆç«¯å’Œæ–‡ä»¶ï¼‰ã€‚å¦‚æœä¸æŒ‡å®šï¼Œåªè¾“å‡ºåˆ°ç»ˆç«¯")
    parser.add_argument("--no-postprocess", action="store_true", 
                       help="ç¦ç”¨åå¤„ç†ï¼Œè¾“å‡ºåŸå§‹æ•°æ®è¡¨æ ¼ï¼ˆé»˜è®¤å¯ç”¨åå¤„ç†ï¼‰")
    parser.add_argument("--mia-only", action="store_true",
                       help="ä»…ç”Ÿæˆå®éªŒ3 (MIA) çš„ç»“æœè¡¨æ ¼")
    parser.add_argument("--mia-exp-name", type=str, default='exp3-mia',
                       help="MIAå®éªŒç»„åï¼ˆé»˜è®¤: exp3-miaï¼‰")
    
    args = parser.parse_args()
    
    # è®¾ç½®è¾“å‡ºæ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    output_file = None
    if args.output_file:
        output_file = args.output_file
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ‰©å±•åï¼Œé»˜è®¤ä½¿ç”¨ .txt
        if not output_file.suffix:
            output_file = output_file.with_suffix('.txt')
        print(f"ğŸ“ è¾“å‡ºå°†åŒæ—¶ä¿å­˜åˆ°æ–‡ä»¶: {output_file}")
    
    # ä½¿ç”¨ TeeOutput åŒæ—¶è¾“å‡ºåˆ°ç»ˆç«¯å’Œæ–‡ä»¶
    with TeeOutput(output_file) as tee:
        if output_file:
            sys.stdout = tee
        
            configs_to_run = []
            any_flag = False
            for arg_attr in EXP_ARG_MAP.keys():
                if getattr(args, arg_attr, False):
                    any_flag = True
                    for key in EXP_ARG_MAP[arg_attr][0]:
                        if key not in configs_to_run: configs_to_run.append(key)
            
            if not any_flag:
                configs_to_run = list(EXPERIMENT_CONFIGS.keys())

            enable_postprocess = not args.no_postprocess  # é»˜è®¤å¯ç”¨åå¤„ç†
            
            for key in configs_to_run:
                if key in EXPERIMENT_CONFIGS:
                    # å¯¹äº EXPERIMENT_2_ABLATIONï¼Œä½¿ç”¨ä¸“é—¨çš„è¡¨æ ¼ç”Ÿæˆå‡½æ•°
                    if key == 'EXPERIMENT_2_ABLATION':
                        generate_exp2_ablation_table(
                            config_key=key,
                            config=EXPERIMENT_CONFIGS[key],
                            output_dir=args.output_dir,
                            tail_epochs=args.tail_epochs,
                            enable_postprocess=enable_postprocess
                        )
                    # å¯¹äº EXPERIMENT_3_Sensitivity_Analysis_rankï¼Œä½¿ç”¨ä¸“é—¨çš„è¡¨æ ¼ç”Ÿæˆå‡½æ•°
                    elif key == 'EXPERIMENT_3_Sensitivity_Analysis_rank':
                        generate_exp3_rank_table(
                            config_key=key,
                            config=EXPERIMENT_CONFIGS[key],
                            output_dir=args.output_dir,
                            tail_epochs=args.tail_epochs,
                            enable_postprocess=enable_postprocess
                        )
                    # å¯¹äº EXPERIMENT_3_Sensitivity_Analysis_sepfpl_topkï¼Œä½¿ç”¨ä¸“é—¨çš„è¡¨æ ¼ç”Ÿæˆå‡½æ•°
                    elif key == 'EXPERIMENT_3_Sensitivity_Analysis_sepfpl_topk':
                        generate_exp3_topk_table(
                            config_key=key,
                            config=EXPERIMENT_CONFIGS[key],
                            output_dir=args.output_dir,
                            tail_epochs=args.tail_epochs,
                            enable_postprocess=enable_postprocess
                        )
                    # å¯¹äº EXPERIMENT_3_Sensitivity_Analysis_rdp_pï¼Œä½¿ç”¨ä¸“é—¨çš„è¡¨æ ¼ç”Ÿæˆå‡½æ•°
                    elif key == 'EXPERIMENT_3_Sensitivity_Analysis_rdp_p':
                        generate_exp3_rdp_p_table(
                            config_key=key,
                            config=EXPERIMENT_CONFIGS[key],
                            output_dir=args.output_dir,
                            tail_epochs=args.tail_epochs,
                            enable_postprocess=enable_postprocess
                        )
                    # å¯¹äº EXPERIMENT_4_MIAï¼Œä½¿ç”¨ä¸“é—¨çš„è¡¨æ ¼ç”Ÿæˆå‡½æ•°
                    elif key == 'EXPERIMENT_4_MIA':
                        generate_exp4_mia_table(
                            config_key=key,
                            config=EXPERIMENT_CONFIGS[key],
                            output_dir=args.output_dir,
                            enable_postprocess=enable_postprocess
                        )
                    # å¯¹äº EXPERIMENT_1_STANDARD å’Œ EXPERIMENT_1_EXTENSIONï¼Œä½¿ç”¨ä¸“é—¨çš„è¡¨æ ¼ç”Ÿæˆå‡½æ•°
                    elif key in ['EXPERIMENT_1_STANDARD', 'EXPERIMENT_1_EXTENSION']:
                        generate_exp1_table(
                            config_key=key,
                            config=EXPERIMENT_CONFIGS[key],
                            output_dir=args.output_dir,
                            tail_epochs=args.tail_epochs,
                            enable_postprocess=enable_postprocess
                        )
                    else:
                        generate_tables(key, EXPERIMENT_CONFIGS[key], args.output_dir, args.tail_epochs, enable_postprocess)
        
        if output_file:
            sys.stdout = tee.console
            print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ°æ–‡ä»¶: {output_file}")

if __name__ == "__main__":
    main()