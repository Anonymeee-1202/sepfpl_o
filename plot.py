import argparse
import pickle
import sys
from pathlib import Path
from statistics import mean, stdev
from typing import List, Dict, Any, Optional, Tuple

import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import numpy as np
import seaborn as sns
from mpl_toolkits.mplot3d import Axes3D
from mpl_toolkits.mplot3d.art3d import Poly3DCollection

from matplotlib.collections import PolyCollection


# å°è¯•å¯¼å…¥å¤–éƒ¨é…ç½®
try:
    from run_main import EXPERIMENT_CONFIGS
except ImportError:
    print("âŒ é”™è¯¯: æ— æ³•å¯¼å…¥ 'run_main.py'ã€‚è¯·ç¡®ä¿è¯¥æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹æˆ– PYTHONPATH ä¸­ã€‚")
    sys.exit(1)

# å¯¼å…¥å…±äº«çš„æ•°æ®å·¥å…·å‡½æ•°
from utils.data_utils import (
    DEFAULT_TAIL_EPOCHS,
    tail_values,
    load_metrics,
    find_output_file,
    postprocess_results,
    extract_value,
    read_data,
    read_scheme,
)

# ========== å…¨å±€é…ç½® ==========
# æ³¨æ„ï¼šé»˜è®¤ä½¿ç”¨outputsç›®å½•ï¼ˆä¸table.pyä¸€è‡´ï¼‰ï¼Œå¦‚æœæ•°æ®åœ¨p_outputsï¼Œè¯·ä½¿ç”¨--output-dirå‚æ•°æŒ‡å®š
DEFAULT_OUTPUT_DIR = Path.home() / 'code/sepfpl/outputs'
DEFAULT_FIG_DIR = Path('figures')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'Liberation Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("husl")


# ========== æ•°æ®è¯»å–å‡½æ•°ï¼ˆå¤ç”¨ data_utils çš„é€»è¾‘ï¼‰ ==========

def read_accuracy(exp_name: str, dataset: str, factorization: str, rank: int,
                  noise: float, seed_list: List[int], num_users: Optional[int],
                  output_base_dir: Path, tail_epochs: int, use_neighbor: bool = False) -> Tuple[float, float]:
    """
    è¯»å–å‡†ç¡®ç‡æ•°æ®ï¼Œè¿”å›å‡å€¼å’Œæ ‡å‡†å·®
    
    Args:
        use_neighbor: å¦‚æœ Trueï¼Œè¿”å› neighbor accuracyï¼›å¦åˆ™è¿”å› local accuracy
    """
    per_seed_values = []
    base_dir = output_base_dir / exp_name / dataset

    for seed in seed_list:
        if num_users is not None:
            pattern = f'acc_{factorization}_{rank}_{noise}_{seed}_{num_users}'
        else:
            pattern = f'acc_{factorization}_{rank}_{noise}_{seed}'
        
        file_path = find_output_file(base_dir, pattern)
        if not file_path:
            continue
        
        local_hist, neighbor_hist = load_metrics(file_path)
        hist = neighbor_hist if use_neighbor else local_hist
        if hist:
            per_seed_values.extend(tail_values(hist, tail_epochs))
    
    if not per_seed_values:
        return 0.0, 0.0
    
    avg = mean(per_seed_values)
    std = stdev(per_seed_values) if len(per_seed_values) > 1 else 0.0
    return avg, std

def _parse_stat_value(stat_str: str) -> Tuple[float, float]:
    """å°† '85.20 Â± 1.05' è§£æä¸º (85.20, 1.05)ã€‚"""
    if not stat_str or stat_str == "N/A":
        return 0.0, 0.0
    try:
        parts = stat_str.split('Â±')
        mean_val = float(parts[0].strip())
        std_val = float(parts[1].strip()) if len(parts) > 1 else 0.0
        return mean_val, std_val
    except (ValueError, IndexError):
        return 0.0, 0.0

def plot_ablation_study(save_name="ablation_study_comparison"):
    """
    ç»˜åˆ¶é¡¶åˆŠå­¦æœ¯é£æ ¼çš„æ¶ˆèå®éªŒåˆ†ç»„æŸ±çŠ¶å›¾ã€‚
    ç‰¹ç‚¹ï¼šTimes New Romanå­—ä½“ã€å¤§å­—å·ã€ä¸“ä¸šé…è‰²ã€çº¹ç†å¡«å……ã€å»è¾¹æ¡†ã€‚
    """
    
    # ================= 0. å…¨å±€æ ·å¼è®¾ç½® (Academic Style) =================
    # ä½¿ç”¨å­—å…¸æ›´æ–° rcParamsï¼Œç¡®ä¿æ— éœ€å®‰è£…é¢å¤–åŒ…å³å¯è·å¾—å­¦æœ¯é£æ ¼
    academic_params = {
        'font.family': 'serif',
        'font.serif': ['Times New Roman', 'DejaVu Serif', 'Liberation Serif', 'serif'],  # å­—ä½“å›é€€
        'font.size': 14 + 4,
        'axes.labelsize': 16 * 1.2,
        'axes.titlesize': 18 * 1.2,
        'xtick.labelsize': 14 * 1.2,
        'ytick.labelsize': 14 * 1.2,
        'legend.fontsize': 20,
        'figure.titlesize': 20 * 1.2,
        'axes.linewidth': 1.5,   # åæ ‡è½´çº¿å˜ç²—
        'xtick.major.width': 1.5,
        'ytick.major.width': 1.5,
        'lines.linewidth': 1.5,  # è¯¯å·®æ£’å˜ç²—
        'mathtext.fontset': 'stix', # æ•°å­¦å…¬å¼å­—ä½“ä¸ Times æ›´æ­
    }
    plt.rcParams.update(academic_params)

    # ================= 1. æ•°æ®å‡†å¤‡ =================
    data = {
        "Caltech-101": {
            "Local Accuracy": {
                "Baseline":     [92.57, 91.73, 87.74],
                "w/ TA":        [94.34, 93.76, 88.88],
                "w/ SE":        [94.96, 94.32, 89.08],
                "SepFPL (Ours)":[95.42, 94.52, 90.46]
            },
            "Neighbor Accuracy": {
                "Baseline":     [91.93, 91.26, 87.37],
                "w/ TA":        [92.81, 91.46, 88.65],
                "w/ SE":        [92.86, 92.85, 89.30],
                "SepFPL (Ours)":[93.40, 92.86, 89.77]
            },
            "Local Std": {
                "Baseline":     [0.95, 1.29, 1.27],
                "w/ TA":        [0.34, 0.41, 1.11],
                "w/ SE":        [0.40, 0.42, 0.94],
                "SepFPL (Ours)":[0.72, 0.44, 0.94]
            },
            "Neighbor Std": {
                "Baseline":     [0.61, 0.70, 1.00],
                "w/ TA":        [0.60, 0.63, 0.89],
                "w/ SE":        [0.51, 0.29, 1.46],
                "SepFPL (Ours)":[0.37, 0.35, 1.05]
            }
        },
        "Stanford Dogs": {
            "Local Accuracy": {
                "Baseline":     [59.94, 58.29, 54.95],
                "w/ TA":        [60.08, 58.95, 55.00],
                "w/ SE":        [62.40, 61.17, 56.60],
                "SepFPL (Ours)":[64.53, 63.36, 56.71]
            },
            "Neighbor Accuracy": {
                "Baseline":     [59.35, 58.59, 53.83],
                "w/ TA":        [59.50, 58.84, 53.93],
                "w/ SE":        [60.77, 60.46, 55.16],
                "SepFPL (Ours)":[61.92, 61.16, 55.97]
            },
            "Local Std": {
                "Baseline":     [1.04, 0.90, 0.56],
                "w/ TA":        [0.78, 0.61, 0.92],
                "w/ SE":        [0.88, 0.40, 1.18],
                "SepFPL (Ours)":[0.95, 1.05, 1.26]
            },
            "Neighbor Std": {
                "Baseline":     [0.81, 0.59, 0.89],
                "w/ TA":        [0.75, 0.91, 1.11],
                "w/ SE":        [0.73, 0.72, 0.73],
                "SepFPL (Ours)":[0.50, 0.32, 0.81]
            }
        }
    }

    # ================= 2. ç»˜å›¾é…ç½® =================
    datasets = ["Caltech-101", "Stanford Dogs"]
    metrics = ["Local Accuracy", "Neighbor Accuracy"]
    epsilon_labels = ["0.4", "0.1", "0.01"]
    # ç»Ÿä¸€ Key åç§°ä»¥åŒ¹é…æ•°æ®
    methods = ["Baseline", "w/ TA", "w/ SE", "SepFPL (Ours)"]
    
    # --- å­¦æœ¯é…è‰²æ–¹æ¡ˆ (Color Palette) ---
    # 1. ç°è‰²ç³» (Baseline): ä½è°ƒå¯¹æ¯”
    # 2. è“è‰²ç³» (TA): å†·è‰²è°ƒ
    # 3. ç»¿è‰²ç³» (SE): å†·è‰²è°ƒ
    # 4. çº¢è‰²/æ©™è‰²ç³» (Ours): æš–è‰²è°ƒï¼Œé«˜äº®çªå‡º
    colors = ['#E0E0E0', '#99C1C2', '#8DA0CB', '#FC8D62'] 
    
    # --- çº¹ç†å¡«å…… (Hatching) ---
    # å¢åŠ é»‘ç™½æ‰“å°æ—¶çš„è¾¨è¯†åº¦
    # '/' = æ–œçº¿, '.' = ç‚¹, 'x' = äº¤å‰, '' = æ— 
    hatches = ['///', '...', 'xx', ''] 

    x = np.arange(len(epsilon_labels))
    width = 0.2 

    # åˆå§‹åŒ–ç”»å¸ƒï¼š2è¡Œ2åˆ—ï¼Œå¢åŠ  DPI ä¿è¯æ¸…æ™°åº¦
    fig, axes = plt.subplots(2, 2, figsize=(14, 11), sharex=True, dpi=300)

    # ================= 3. å¾ªç¯ç»˜å›¾ =================
    for row_idx, dataset in enumerate(datasets):
        for col_idx, metric in enumerate(metrics):
            ax = axes[row_idx, col_idx]
            
            # æ•°æ®æå–
            y_data = data[dataset][metric]
            std_key = "Local Std" if metric == "Local Accuracy" else "Neighbor Std"
            y_err = data[dataset][std_key]
            
            # ç»˜åˆ¶æŸ±å­
            for i, method in enumerate(methods):
                offset = (i - 1.5) * width
                
                # å›¾ä¾‹ Label ä»…åœ¨ç¬¬ä¸€ä¸ªå­å›¾è®¾ç½®
                label = method if (row_idx == 0 and col_idx == 0) else ""
                
                # ç»˜åˆ¶æŸ±çŠ¶å›¾
                bars = ax.bar(x + offset, y_data[method], width, 
                              label=label,
                              color=colors[i], 
                              edgecolor='black', # é»‘è‰²è¾¹æ¡†
                              linewidth=1.2,     # è¾¹æ¡†å®½åº¦
                              alpha=1.0,         # ä¸é€æ˜
                              yerr=y_err[method], 
                              capsize=4,         # è¯¯å·®æ£’å¸½å­å®½åº¦
                              error_kw={'elinewidth': 1.5, 'ecolor': '#333333'}, # è¯¯å·®æ£’æ ·å¼
                              zorder=3)          # ç¡®ä¿æŸ±å­åœ¨ç½‘æ ¼çº¿ä¹‹ä¸Š
                
                # åº”ç”¨çº¹ç† (Hatching)
                # æ³¨æ„ï¼šmatplotlib çš„ hatch é¢œè‰²é»˜è®¤éš edgecolorï¼Œ
                # è¿™é‡Œæˆ‘ä»¬ä¿æŒé»‘è‰²è¾¹æ¡†ï¼Œçº¹ç†ä¹Ÿæ˜¯é»‘è‰²çš„
                for bar in bars:
                    bar.set_hatch(hatches[i])

            # --- æ ·å¼å¾®è°ƒ ---
            # æ ‡é¢˜ä¸åæ ‡è½´
            ax.set_title(f"{dataset} - {metric}", fontweight='bold', pad=12)
            
            if row_idx == 1:
                ax.set_xlabel(r"Privacy Budget ($\epsilon$)", fontweight='bold')
                ax.set_xticks(x)
                ax.set_xticklabels(epsilon_labels)
            
            if col_idx == 0:
                ax.set_ylabel("Accuracy (%)", fontweight='bold')

            # --- æ ¸å¿ƒç¾åŒ–ï¼šç½‘æ ¼ä¸è¾¹æ¡† ---
            # ä»…ä¿ç•™ Y è½´ç½‘æ ¼ï¼Œè™šçº¿ï¼Œç°è‰²ï¼Œç½®äºåº•å±‚
            ax.grid(axis='y', linestyle='--', alpha=0.6, color='gray', zorder=0)
            
            # ç§»é™¤é¡¶éƒ¨å’Œå³ä¾§è¾¹æ¡† (Despine)
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False)
            # åŠ ç²—å·¦ä¾§å’Œåº•éƒ¨è¾¹æ¡†
            ax.spines['left'].set_linewidth(1.5)
            ax.spines['bottom'].set_linewidth(1.5)

            # --- Yè½´èŒƒå›´åŠ¨æ€è°ƒæ•´ ---
            # ç•™å‡ºä¸€ç‚¹å¤´éƒ¨ç©ºé—´ç»™è¯¯å·®æ£’
            if dataset == "Caltech-101":
                ax.set_ylim(85, 99) 
            else:
                ax.set_ylim(45, 70)

    # ================= 4. å…¨å±€å›¾ä¾‹ä¸ä¿å­˜ =================
    # è·å–å›¾ä¾‹å¥æŸ„
    handles, labels = axes[0, 0].get_legend_handles_labels()
    
    # åœ¨é¡¶éƒ¨å±…ä¸­æ”¾ç½®å›¾ä¾‹ï¼Œæ— è¾¹æ¡†ï¼ŒèƒŒæ™¯é€æ˜
    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 1.0), 
               ncol=4, frameon=False, columnspacing=1.5)

    plt.tight_layout()
    # è°ƒæ•´é¡¶éƒ¨è¾¹è·ï¼Œé˜²æ­¢æ ‡é¢˜è¢«å›¾ä¾‹é®æŒ¡
    # å‡å°‘ä¸Šä¸‹å­å›¾é—´è·(hspace)ï¼Œå¢åŠ å›¾å’Œå›¾ä¾‹ä¹‹é—´çš„é—´è·(topé™ä½)
    plt.subplots_adjust(top=0.88, hspace=0.15, wspace=0.15) 

    # è·¯å¾„å¤„ç†
    save_dir = Path("figures") # æˆ–è€…æ˜¯ DEFAULT_FIG_DIR
    save_dir.mkdir(exist_ok=True)
    
    pdf_path = save_dir / f"{save_name}.pdf"
    
    plt.savefig(pdf_path, bbox_inches='tight')

    print(f"âœ… å­¦æœ¯å›¾è¡¨å·²ç”Ÿæˆ:\n - {pdf_path}")
    
    plt.close()


# ================= æ•æ„Ÿæ€§åˆ†æ3D Ribbonå›¾ç»˜åˆ¶å™¨ =================
class SensitivityAnalysisPlotter:
    """
    å‚æ•°æ•æ„Ÿæ€§åˆ†æ3D Ribbonå›¾ç»˜åˆ¶å™¨
    
    å°è£…äº†ç»˜åˆ¶å‚æ•°æ•æ„Ÿæ€§åˆ†ææ‰€éœ€çš„æ‰€æœ‰åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - å­¦æœ¯é£æ ¼é…ç½®
    - æ•°æ®å‡†å¤‡
    - 3D Ribbonå­å›¾ç»˜åˆ¶
    - å®Œæ•´å›¾è¡¨ç”Ÿæˆ
    """
    
    @staticmethod
    def _set_academic_style():
        """é…ç½®å­¦æœ¯é£æ ¼çš„ç»˜å›¾å‚æ•°"""
        plt.rcParams.update({
        'font.family': 'serif',
        'font.serif': ['Times New Roman', 'DejaVu Serif', 'Liberation Serif', 'serif'],
        'font.size': 12 + 4,
        'axes.labelsize': 14 + 2,
        'axes.titlesize': 16,
        'xtick.labelsize': 12 + 4,
        'ytick.labelsize': 12 + 4,
        'legend.fontsize': 16,
        'mathtext.fontset': 'stix',
        'figure.titlesize': 18,
        'axes.linewidth': 1.0,
        'grid.linewidth': 0.5,
        'grid.alpha': 0.3,
        'grid.linestyle': '--'
        })
    
    @staticmethod
    def _get_data():
        """è¿”å›å°è£…å¥½çš„å®éªŒæ•°æ®"""
        # éšç§é¢„ç®—æ ‡ç­¾ (ç”¨äºYè½´)
        # Group A: Rank & TopK (å« Noise=0)
        eps_labels_A = [r'$\epsilon=0.01$', r'$\epsilon=0.1$', r'$\epsilon=0.4$', r'$\epsilon=\infty$'] 
        # Group B: p (ä¸å« Noise=0)
        eps_labels_B = [r'$\epsilon=0.01$', r'$\epsilon=0.1$', r'$\epsilon=0.4$']

        # é¢œè‰²é…ç½® (ç”¨äºä¸åŒ Epsilon)
        # ä½¿ç”¨æ¸å˜è‰²ï¼šæ·±è“ -> è“ -> æµ…è“ -> ç´«(æ— å™ª)
        colors_A = ['#08519c', '#3182bd', '#6baed6', '#9e9ac8'] 
        colors_B = ['#08519c', '#3182bd', '#6baed6']

        # --- Rank Data ---
        rank_x = [1, 2, 4, 8, 16]
        # [Dogs_Loc, Dogs_Ngh, Flowers_Loc, Flowers_Ngh]
        # Data order: [Noise=0, 0.4, 0.1, 0.01] -> Reorder to [0.01, 0.1, 0.4, 0] for plotting (Back to Front)
        # Raw data order from user: 0, 0.4, 0.1, 0.01
        # Target plotting order (y=0..3): 0.01, 0.1, 0.4, 0
        _rank_raw = [
            [[61.15, 61.46, 61.21, 59.01, 60.43], [58.35, 59.60, 60.32, 60.61, 61.19], [58.28, 60.28, 60.10, 59.14, 61.10], [56.24, 58.13, 57.32, 56.92, 56.84]], # Dogs Loc
            [[61.97, 61.60, 60.55, 59.40, 59.94], [58.62, 59.41, 59.67, 60.19, 60.76], [57.57, 59.55, 59.94, 59.62, 59.77], [56.72, 57.27, 56.29, 56.15, 56.71]], # Dogs Ngh
            [[69.81, 71.43, 69.16, 70.03, 68.85], [69.46, 70.95, 68.95, 70.99, 70.60], [69.86, 70.76, 67.66, 70.14, 69.85], [66.79, 66.42, 66.08, 66.08, 65.63]], # Flowers Loc
            [[70.65, 71.24, 69.54, 69.54, 69.47], [69.25, 70.95, 68.63, 71.13, 70.36], [69.81, 70.37, 66.64, 69.71, 69.92], [66.27, 65.94, 65.66, 65.77, 66.85]]  # Flowers Ngh
        ]
        # Reorder function: [0, 1, 2, 3] -> [3, 2, 1, 0] to match labels [0.01, 0.1, 0.4, 0]
        # User Raw: 0(idx0), 0.4(idx1), 0.1(idx2), 0.01(idx3)
        # Target:   0.01, 0.1, 0.4, 0
        reorder_idx_A = [3, 2, 1, 0] 
        rank_data = [[dataset[i] for i in reorder_idx_A] for dataset in _rank_raw]

        # --- TopK Data ---
        topk_x = [2, 4, 6, 8]
        _topk_raw = [
            [[59.16, 59.22, 58.87, 59.01], [60.67, 60.49, 60.10, 60.61], [59.65, 59.85, 60.04, 59.14], [58.39, 56.50, 57.49, 56.92]],
            [[59.70, 60.34, 59.74, 59.40], [60.40, 60.16, 60.13, 60.19], [59.55, 59.81, 59.51, 59.62], [58.09, 56.19, 57.01, 56.15]],
            [[70.27, 70.17, 69.88, 70.03], [71.27, 71.27, 70.78, 70.99], [70.61, 70.41, 70.67, 70.14], [66.47, 66.28, 65.58, 66.08]],
            [[69.67, 69.53, 69.30, 69.54], [70.95, 70.66, 70.19, 71.13], [69.96, 70.13, 70.09, 69.71], [66.36, 66.01, 65.58, 65.77]]
        ]
        topk_data = [[dataset[i] for i in reorder_idx_A] for dataset in _topk_raw]

        # --- P Data ---
        p_x = [0, 0.2, 0.5, 1]
        # User Raw: 0.4(idx0), 0.1(idx1), 0.01(idx2)
        # Target:   0.01, 0.1, 0.4
        reorder_idx_B = [2, 1, 0]
        _p_raw = [
            [[60.61, 60.66, 59.86, 60.27], [59.56, 60.36, 60.06, 59.14], [56.92, 58.28, 56.47, 57.22]],
            [[60.18, 60.19, 59.77, 59.68], [59.73, 59.91, 59.62, 59.91], [56.15, 58.52, 56.03, 55.96]],
            [[70.65, 71.19, 70.99, 70.91], [70.14, 70.50, 69.89, 69.61], [66.08, 67.08, 65.07, 60.65]],
            [[70.36, 71.13, 70.35, 70.21], [69.81, 70.10, 69.71, 69.24], [65.77, 67.00, 64.97, 59.53]]
        ]
        p_data = [[dataset[i] for i in reorder_idx_B] for dataset in _p_raw]

        return {
            "params": [
                {"data": rank_data, "x": rank_x, "xlabel": "Rank ($r$)", "title": "(a) Impact of Rank", "eps_labels": eps_labels_A, "colors": colors_A},
                {"data": topk_data, "x": topk_x, "xlabel": "TopM ($M$)", "title": "(b) Impact of TopK", "eps_labels": eps_labels_A, "colors": colors_A},
                {"data": p_data,   "x": p_x,    "xlabel": r"Schedule Factor ($p$)", "title": "(c) Impact of $p$", "eps_labels": eps_labels_B, "colors": colors_B}
            ],
            "datasets": [
                {"name": "Stanford Dogs", "indices": [0, 1], "zlim": (55, 63)},
                {"name": "Oxford Flowers", "indices": [2, 3], "zlim": (58, 72)}
            ]
        }
    
    @staticmethod
    def _adjust_color_for_neighbor(color, lighten_factor=0.25, shift_hue=0.05):
        """è°ƒæ•´é¢œè‰²ç”¨äº Neighbor çº¿æ¡ï¼šå˜æµ…å¹¶ç•¥å¾®å‘çº¢è‰²è°ƒåç§»"""
        import matplotlib.colors as mcolors
        rgb = mcolors.to_rgb(color)
        # å‘ç™½è‰²æ–¹å‘æ··åˆï¼ˆå˜æµ…ï¼‰
        lightened = tuple(1 - (1 - c) * (1 - lighten_factor) for c in rgb)
        # ç•¥å¾®å¢åŠ çº¢è‰²åˆ†é‡ï¼Œä½¿é¢œè‰²æ›´æš–
        adjusted = (min(1.0, lightened[0] + shift_hue), lightened[1], lightened[2])
        return adjusted
    
    @staticmethod
    def _plot_ribbon_subplot(ax, x_vals, dataset_data, eps_labels, colors, xlabel, title, zlim, show_zlabel=True):
        """
        åœ¨ç»™å®šçš„ 3D è½´ä¸Šç»˜åˆ¶å•ä¸ªå‚æ•°çš„ Ribbon å›¾ã€‚
        
        Args:
            ax: 3D åæ ‡è½´å¯¹è±¡
            x_vals: Xè½´æ•°å€¼åˆ—è¡¨
            dataset_data: [loc_data_list, ngh_data_list]ï¼ŒåŒ…å« Local å’Œ Neighbor æ•°æ®
            eps_labels: éšç§é¢„ç®—æ ‡ç­¾åˆ—è¡¨
            colors: é¢œè‰²åˆ—è¡¨
            xlabel: Xè½´æ ‡ç­¾
            title: å­å›¾æ ‡é¢˜
            zlim: Zè½´èŒƒå›´ (min, max)
            show_zlabel: æ˜¯å¦æ˜¾ç¤ºzè½´æ ‡ç­¾ï¼Œé»˜è®¤True
        """
        # è°ƒæ•´è§†è§’
        ax.view_init(elev=20, azim=-70)
        
        num_eps = len(eps_labels)
        xs = np.arange(len(x_vals))
        
        # è¾…åŠ©å‡½æ•°ï¼šç»˜åˆ¶å•æ¡ Ribbon
        def add_ribbon(y_index, z_values, color, label=None, linestyle='-', is_neighbor=False):
            # 1. é¡¶éƒ¨çº¿æ¡
            line_color = SensitivityAnalysisPlotter._adjust_color_for_neighbor(color) if is_neighbor else color
            line_width = 2.2 if not is_neighbor else 2.0  # Local çº¿æ¡æ›´ç²—ï¼Œæ›´çªå‡º
            ax.plot(xs, [y_index]*len(xs), z_values, 
                    color=line_color, linewidth=line_width, linestyle=linestyle,
                    marker='o', markersize=5 if not is_neighbor else 4, 
                    markerfacecolor='white', markeredgecolor=line_color, markeredgewidth=1.5,
                    zorder=10 + y_index, label=label)
            
            # 2. å¡«å……é¢ (PolyCollection) - ä»…ç”¨äº Local
            if not is_neighbor:
                verts = []
                # åº•éƒ¨åŸºå‡†çº¿ (z=zmin)
                z_min = zlim[0]
                polygon = [(x, z_min) for x in xs] + [(x, z) for x, z in zip(xs, z_values)][::-1]
                verts.append(polygon)
                
                # ä½¿ç”¨ç¨æ·±çš„é¢œè‰²ç”¨äºå¡«å……ï¼Œå¢åŠ å¯¹æ¯”åº¦
                poly = PolyCollection(verts, facecolors=color, edgecolors=color, 
                                     alpha=0.4, linewidths=0.5) # é™ä½é€æ˜åº¦ï¼Œæ·»åŠ è¾¹æ¡†
                ax.add_collection3d(poly, zs=y_index, zdir='y')
        
        # è·å– Local å’Œ Neighbor æ•°æ®
        loc_data_list = dataset_data[0]
        ngh_data_list = dataset_data[1]

        for i in range(num_eps):
            # é¢œè‰²ï¼šè¶Šé å‰ï¼ˆepsilon è¶Šå°ï¼‰é¢œè‰²è¶Šæ·±ï¼Œæˆ–è€…åä¹‹
            c = colors[i]
            
            # ç»˜åˆ¶ Local Ribbonï¼ˆå®çº¿ï¼Œå¸¦å¡«å……ï¼‰
            add_ribbon(i, loc_data_list[i], c, label=f"{eps_labels[i]}" if i==0 else None, 
                      linestyle='-', is_neighbor=False)
            
            # ç»˜åˆ¶ Neighbor Lineï¼ˆè™šçº¿ï¼Œæ— å¡«å……ï¼Œä½¿ç”¨ç¨æµ…çš„é¢œè‰²ï¼‰
            add_ribbon(i, ngh_data_list[i], c, linestyle='--', is_neighbor=True)

        # --- åæ ‡è½´è®¾ç½® ---
        # Xè½´
        ax.set_xticks(xs)
        ax.set_xticklabels([str(x) for x in x_vals])
        ax.set_xlabel(xlabel, labelpad=8, fontweight='bold')
        
        # Yè½´
        ax.set_yticks(np.arange(num_eps))
        ax.set_yticklabels(eps_labels, verticalalignment='baseline', horizontalalignment='left')
        # è°ƒæ•´ Y è½´æ ‡ç­¾è§’åº¦
        plt.setp(ax.get_yticklabels(), fontsize=12 + 4)
        
        # Zè½´
        ax.set_zlim(zlim)
        if show_zlabel:
            ax.set_zlabel("Accuracy (%)", fontweight='bold', labelpad=8)
        
        # ä¼˜åŒ–é¢æ¿æ˜¾ç¤º - ä½¿ç”¨æ›´æ¸…æ™°çš„èƒŒæ™¯è‰²
        pane_color = '#f0f0f5'  # æ·¡è“ç°è‰²
        
        ax.xaxis.pane.fill = True
        ax.xaxis.pane.set_facecolor(pane_color)
        ax.xaxis.pane.set_alpha(0.3)
        
        ax.yaxis.pane.fill = True
        ax.yaxis.pane.set_facecolor(pane_color)
        ax.yaxis.pane.set_alpha(0.3)
        
        ax.zaxis.pane.fill = True
        ax.zaxis.pane.set_facecolor(pane_color)
        ax.zaxis.pane.set_alpha(0.3)
        
        # è®¾ç½®åæ ‡è½´é¢œè‰²ï¼Œå¢å¼ºå¯è§æ€§
        ax.xaxis.line.set_color('#666666')
        ax.yaxis.line.set_color('#666666')
        ax.zaxis.line.set_color('#666666')
        
        ax.grid(False) # ç§»é™¤é»˜è®¤ç½‘æ ¼
        
        # æ‰‹åŠ¨æ·»åŠ  Z è½´ç½‘æ ¼çº¿ (ä»…åœ¨èƒŒæ¿) - ä½¿ç”¨æ›´æ˜æ˜¾çš„é¢œè‰²
        for z in np.linspace(zlim[0], zlim[1], 5):
            ax.plot([xs[0], xs[-1]], [num_eps-1, num_eps-1], [z, z], 
                    color='#999999', alpha=0.3, linestyle='--', linewidth=0.8)

    @classmethod
    def plot(cls, save_name="sensitivity_analysis_refined", show_plot=True):
        """
        ç”Ÿæˆå‚æ•°æ•æ„Ÿæ€§åˆ†æçš„3D Ribbonå›¾
        
        Args:
            save_name: ä¿å­˜æ–‡ä»¶åå‰ç¼€
            show_plot: æ˜¯å¦æ˜¾ç¤ºå›¾è¡¨ï¼ˆé»˜è®¤Trueï¼ŒFalseåˆ™åªä¿å­˜ï¼‰
        """
        cls._set_academic_style()
        data_pack = cls._get_data()
        
        # ä¸ºæ¯ä¸ªæ•°æ®é›†ç”Ÿæˆä¸€å¼ å¤§å›¾ (1è¡Œ3åˆ—)
        for ds_conf in data_pack["datasets"]:
            ds_name = ds_conf["name"]
            indices = ds_conf["indices"] # [loc_idx, ngh_idx]
            zlim = ds_conf["zlim"]
            
            fig = plt.figure(figsize=(18, 6))
            
            num_params = len(data_pack["params"])
            for i, param_conf in enumerate(data_pack["params"]):
                ax = fig.add_subplot(1, 3, i+1, projection='3d')
                
                # æå–è¯¥å‚æ•°ä¸‹ï¼Œè¯¥æ•°æ®é›†çš„ Local å’Œ Neighbor æ•°æ®
                current_ds_data = [param_conf["data"][indices[0]], param_conf["data"][indices[1]]]
                
                # åªæœ‰æœ€å³è¾¹çš„å­å›¾ï¼ˆæœ€åä¸€ä¸ªï¼‰æ˜¾ç¤ºzè½´æ ‡ç­¾
                show_zlabel = (i == num_params - 1)
                
                cls._plot_ribbon_subplot(
                    ax, 
                    param_conf["x"], 
                    current_ds_data, 
                    param_conf["eps_labels"], 
                    param_conf["colors"], 
                    param_conf["xlabel"], 
                    param_conf["title"],
                    zlim,
                    show_zlabel=show_zlabel
                )
                
                # æ·»åŠ è‡ªå®šä¹‰å›¾ä¾‹ (ä»…åœ¨æœ€åä¸€ä¸ªå­å›¾)
                if i == num_params - 1:
                    from matplotlib.lines import Line2D
                    legend_elements = [
                        Line2D([0], [0], color='black', lw=2, label='Local Acc.'),
                        Line2D([0], [0], color='black', lw=2, linestyle='--', label='Neighbor Acc.'),
                    ]
                    ax.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1.05, 0.5), fontsize=18, frameon=False)

            plt.subplots_adjust(left=0.1, right=0.90, wspace=0.01)
            
            save_path = Path("figures") / f"{save_name}_{ds_name.lower().replace(' ', '_')}.pdf"
            save_path.parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(save_path, bbox_inches='tight', dpi=300)
            print(f"Saved: {save_path}")
            
            if show_plot:
                plt.show()
            else:
                plt.close()

# ================= MIAåˆ†æç»˜å›¾ç±» =================
class MiaAnalysisPlotter:
    """
    MIAåˆ†æç»˜å›¾ç±»ï¼Œç”¨äºç»˜åˆ¶åŒ…å«3ä¸ªå­å›¾çš„ç»¼åˆåˆ†æå›¾ï¼š
    1. Local Accuracy vs Privacy Budget
    2. Neighbor Accuracy vs Privacy Budget
    3. MIA Attack Success Rate vs Privacy Budget
    """
    
    def __init__(self, output_dir: Path = DEFAULT_OUTPUT_DIR, 
                 tail_epochs: int = DEFAULT_TAIL_EPOCHS,
                 fig_dir: Path = DEFAULT_FIG_DIR):
        """
        åˆå§‹åŒ–ç»˜å›¾å™¨
        
        Args:
            output_dir: æ•°æ®ç›®å½•
            tail_epochs: ç»Ÿè®¡æœ€åNè½®çš„å¹³å‡å€¼
            fig_dir: å›¾ç‰‡ä¿å­˜ç›®å½•
        """
        self.output_dir = output_dir
        self.tail_epochs = tail_epochs
        self.fig_dir = fig_dir
        
        # æ•°æ®é›†æ ‡ç­¾æ˜ å°„ï¼ˆç¾åŒ–æ˜¾ç¤ºï¼‰
        self.dataset_labels = {
            'caltech-101': 'Caltech-101',
            'stanford_dogs': 'Stanford Dogs',
            'oxford_flowers': 'Oxford Flowers',
            'food-101': 'Food-101'
        }
        
        # æ•°æ®é›†é¢œè‰²é…ç½®
        self.dataset_colors = {
            'caltech-101': '#1f77b4',      # Blue
            'oxford_flowers': '#2ca02c',   # Green
            'food-101': '#d62728',         # Red
            'stanford_dogs': '#ff7f0e'      # Orange
        }
        
        # æ•°æ®é›†æ ‡è®°é…ç½®
        self.dataset_markers = {
            'caltech-101': 'o',    # Circle
            'oxford_flowers': '^', # Triangle Up
            'food-101': 'D',       # Diamond
            'stanford_dogs': 's'   # Square
        }
        
        # è®¾ç½®å­¦æœ¯ç»˜å›¾é£æ ¼
        plt.rcParams.update({
            'font.family': 'serif',
            'font.serif': ['Times New Roman', 'DejaVu Serif', 'Liberation Serif', 'serif'],
            'mathtext.fontset': 'stix',
            'font.size': 32,
            'axes.labelsize': 24,
            # 'axes.titlesize': 16,
            'xtick.labelsize': 22,
            'ytick.labelsize': 22,
            'legend.fontsize': 24,
            'axes.linewidth': 1.2,
            'grid.linewidth': 0.8,
            'lines.linewidth': 4,
            'lines.markersize': 12,
        })
    
    def _load_exp1_data(self):
        """åŠ è½½å®éªŒ1 Standardçš„æ•°æ®"""
        import pickle
        
        # ä»é…ç½®è·å–å®éªŒå‚æ•°
        if 'EXPERIMENT_1_STANDARD' not in EXPERIMENT_CONFIGS:
            print("âŒ é”™è¯¯: æ‰¾ä¸åˆ° EXPERIMENT_1_STANDARD é…ç½®")
            return {}, {}, [], []
        
        config = EXPERIMENT_CONFIGS['EXPERIMENT_1_STANDARD']
        exp_name = config.get('exp_name', 'exp1-standard')
        datasets = config.get('dataset_list', [])
        noise_list = config.get('noise_list', [0.0, 0.4, 0.2, 0.1, 0.05, 0.01])
        rank = config.get('rank_list', [8])[0]
        seed_list = config.get('seed_list', [1])
        num_users = config.get('num_users_list', [10])[0]
        sepfpl_topk = config.get('sepfpl_topk', 8)
        rdp_p = config.get('rdp_p', 0.2)
        factorization = 'sepfpl'
        
        # è¯»å–æ•°æ®
        base_dir = self.output_dir / exp_name
        dataset_local_map = {}
        dataset_neighbor_map = {}
        
        for dataset in datasets:
            dataset_dir = base_dir / dataset
            if not dataset_dir.exists():
                print(f"âš ï¸  è­¦å‘Š: æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_dir}")
                continue
            
            local_accs = []
            neighbor_accs = []
            
            for noise in noise_list:
                # æ„å»ºæ–‡ä»¶åæ¨¡å¼
                if noise == int(noise):
                    noise_str = f'{float(noise):.1f}'
                else:
                    noise_str = f'{float(noise):g}'
                
                rdp_p_str = str(rdp_p)
                
                # è¯»å–æ‰€æœ‰seedçš„æ•°æ®å¹¶è®¡ç®—å¹³å‡å€¼
                per_seed_local = []
                per_seed_neighbor = []
                
                for seed in seed_list:
                    pattern = f'acc_{factorization}_{rank}_{noise_str}_{seed}_{sepfpl_topk}_{rdp_p_str}_{num_users}'
                    file_path = find_output_file(dataset_dir, pattern)
                    
                    if file_path and file_path.exists():
                        try:
                            with open(file_path, 'rb') as f:
                                data = pickle.load(f)
                            
                            # æ•°æ®æ ¼å¼å¯èƒ½æ˜¯ [local_acc_list, neighbor_acc_list] æˆ– dict
                            if isinstance(data, list) and len(data) >= 2:
                                local_hist = data[0] if isinstance(data[0], list) else []
                                neighbor_hist = data[1] if isinstance(data[1], list) else []
                            elif isinstance(data, dict):
                                local_hist = data.get('local_acc', [])
                                neighbor_hist = data.get('neighbor_acc', [])
                            else:
                                local_hist, neighbor_hist = [], []
                            
                            # è·å–æœ€å tail_epochs è½®çš„å¹³å‡å€¼
                            if local_hist:
                                tail_local = tail_values(local_hist, self.tail_epochs)
                                if tail_local:
                                    per_seed_local.extend(tail_local)
                            
                            if neighbor_hist:
                                tail_neighbor = tail_values(neighbor_hist, self.tail_epochs)
                                if tail_neighbor:
                                    per_seed_neighbor.extend(tail_neighbor)
                        except Exception as e:
                            print(f"âš ï¸  è­¦å‘Š: æ— æ³•è¯»å– {file_path}: {e}")
                
                # è®¡ç®—è¯¥noiseå€¼ä¸‹çš„å¹³å‡å‡†ç¡®ç‡
                if per_seed_local:
                    local_accs.append(mean(per_seed_local))
                else:
                    local_accs.append(0.0)
                
                if per_seed_neighbor:
                    neighbor_accs.append(mean(per_seed_neighbor))
                else:
                    neighbor_accs.append(0.0)
            
            if local_accs or neighbor_accs:
                dataset_local_map[dataset] = local_accs
                dataset_neighbor_map[dataset] = neighbor_accs
        
        return dataset_local_map, dataset_neighbor_map, noise_list, datasets
    
    def _load_exp4_data(self):
        """åŠ è½½å®éªŒ4 MIAçš„æ•°æ®"""
        import pickle
        
        # ä»é…ç½®è·å–å®éªŒå‚æ•°
        if 'EXPERIMENT_4_MIA' not in EXPERIMENT_CONFIGS:
            print("âŒ é”™è¯¯: æ‰¾ä¸åˆ° EXPERIMENT_4_MIA é…ç½®")
            return {}, [], []
        
        config = EXPERIMENT_CONFIGS['EXPERIMENT_4_MIA']
        exp_name = config.get('exp_name', 'exp4-mia')
        datasets = config.get('dataset_list', [])
        noise_list = config.get('noise_list', [0.0, 0.4, 0.2, 0.1, 0.05, 0.01])
        
        # è¯»å–æ•°æ®
        base_dir = self.output_dir / exp_name
        dataset_acc_map = {}
        
        for dataset in datasets:
            dataset_dir = base_dir / dataset
            if not dataset_dir.exists():
                print(f"âš ï¸  è­¦å‘Š: æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {dataset_dir}")
                continue
            
            accuracies = []
            for noise in noise_list:
                # æ„å»ºæ–‡ä»¶è·¯å¾„
                mia_acc_file = dataset_dir / f'mia_acc_{noise}.pkl'
                if mia_acc_file.exists():
                    try:
                        with open(mia_acc_file, 'rb') as f:
                            data = pickle.load(f)
                        
                        if isinstance(data, dict):
                            avg_acc = data.get('average', 0.0)
                            accuracies.append(avg_acc * 100)  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                        elif isinstance(data, (int, float)):
                            accuracies.append(float(data) * 100)
                        else:
                            print(f"âš ï¸  è­¦å‘Š: {mia_acc_file} æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
                            accuracies.append(0.0)
                    except Exception as e:
                        print(f"âš ï¸  è­¦å‘Š: æ— æ³•è¯»å– {mia_acc_file}: {e}")
                        accuracies.append(0.0)
                else:
                    print(f"âš ï¸  è­¦å‘Š: æ–‡ä»¶ä¸å­˜åœ¨: {mia_acc_file}")
                    accuracies.append(0.0)
            
            if accuracies:
                dataset_acc_map[dataset] = accuracies
        
        return dataset_acc_map, noise_list, datasets
    
    def _plot_subplot(self, ax, acc_map, datasets, noise_list, ylabel, title=None, show_legend=False, y_lim=None):
        """ç»˜åˆ¶å•ä¸ªå­å›¾"""
        x_positions = np.arange(len(noise_list))
        x_tick_labels = ['$\infty$'] + [f'{n}' for n in noise_list[1:]]
        
        # ç»˜åˆ¶æ¯æ¡æŠ˜çº¿
        for dataset in datasets:
            if dataset not in acc_map:
                continue
            
            accuracies = acc_map[dataset]
            label = self.dataset_labels.get(dataset, dataset)
            color = self.dataset_colors.get(dataset, '#333333')
            marker = self.dataset_markers.get(dataset, 'o')
            
            ax.plot(x_positions, accuracies,
                    marker=marker,
                    label=label,
                    color=color,
                    markeredgecolor='white',
                    markeredgewidth=1.5,
                    zorder=10)
        
        # è®¾ç½®æ ‡é¢˜ï¼ˆå¦‚æœæä¾›ï¼‰
        if title:
            ax.set_title(title, fontweight='bold', pad=12)
        ax.set_xlabel(r'Privacy Budget ($\epsilon$)', fontweight='bold')
        ax.set_ylabel(ylabel, fontweight='bold')
        
        # è®¾ç½®Xè½´åˆ»åº¦
        ax.set_xticks(x_positions)
        ax.set_xticklabels(x_tick_labels)
        
        # ç½‘æ ¼å’Œè¾¹æ¡†ç¾åŒ–
        ax.grid(True, linestyle='--', alpha=0.4, color='gray', zorder=0)
        ax.spines['right'].set_visible(False)
        ax.spines['top'].set_visible(False)
        
        # è®¾ç½®Yè½´èŒƒå›´
        if y_lim is not None:
            ax.set_ylim(y_lim)
        else:
            all_accs = [acc for accs in acc_map.values() for acc in accs if acc > 0]
            if all_accs:
                min_acc = min(all_accs)
                max_acc = max(all_accs)
                ax.set_ylim(bottom=max(0, min_acc - 5), top=min(105, max_acc + 5))
        
        # å›¾ä¾‹ï¼ˆåªåœ¨éœ€è¦æ—¶æ˜¾ç¤ºï¼Œä¸”æ”¾åœ¨å³ä¾§ï¼‰
        if show_legend:
            ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), frameon=False)
    
    def plot(self):
        """ç»˜åˆ¶åŒ…å«3ä¸ªå­å›¾çš„ç»¼åˆåˆ†æå›¾"""
        # åŠ è½½æ•°æ®
        dataset_local_map, dataset_neighbor_map, noise_list_exp1, datasets_exp1 = self._load_exp1_data()
        dataset_mia_map, noise_list_exp4, datasets_exp4 = self._load_exp4_data()
        
        if not dataset_local_map and not dataset_neighbor_map:
            print("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°å®éªŒ1çš„ä»»ä½•æ•°æ®")
            return
        
        if not dataset_mia_map:
            print("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°å®éªŒ4çš„ä»»ä½•æ•°æ®")
            return
        
        # ç¡®ä¿ä¸¤ä¸ªå®éªŒä½¿ç”¨ç›¸åŒçš„æ•°æ®é›†å’Œå™ªå£°åˆ—è¡¨
        datasets = list(set(datasets_exp1) & set(datasets_exp4))
        if not datasets:
            print("âŒ é”™è¯¯: ä¸¤ä¸ªå®éªŒæ²¡æœ‰å…±åŒçš„æ•°æ®é›†")
            return
        
        # ä½¿ç”¨å®éªŒ1çš„å™ªå£°åˆ—è¡¨ï¼ˆé€šå¸¸ä¸¤ä¸ªå®éªŒåº”è¯¥ä¸€è‡´ï¼‰
        noise_list = noise_list_exp1
        
        # è®¡ç®— Local å’Œ Neighbor çš„å…±åŒYè½´èŒƒå›´
        all_local_accs = [acc for accs in dataset_local_map.values() for acc in accs if acc > 0]
        all_neighbor_accs = [acc for accs in dataset_neighbor_map.values() for acc in accs if acc > 0]
        all_acc_accs = [acc for accs in dataset_mia_map.values() for acc in accs if acc > 0]
        
        # è®¡ç®— Local å’Œ Neighbor çš„å…±åŒèŒƒå›´
        combined_accs = all_local_accs + all_neighbor_accs
        if combined_accs:
            min_acc = min(combined_accs)
            max_acc = max(combined_accs)
            shared_y_lim = (max(0, min_acc - 5), min(105, max_acc + 5))
        else:
            shared_y_lim = None
        
        # è®¡ç®— MIA çš„Yè½´èŒƒå›´
        if all_acc_accs:
            min_mia = min(all_acc_accs)
            max_mia = max(all_acc_accs)
            mia_y_lim = (max(0, min_mia - 5), min(105, max_mia + 5))
        else:
            mia_y_lim = None
        
        # åˆ›å»ºåŒ…å«3ä¸ªå­å›¾çš„figure
        fig, axes = plt.subplots(1, 3, figsize=(24, 6))
        
        # ç»˜åˆ¶ç¬¬ä¸€ä¸ªå­å›¾ï¼šLocal Accuracyï¼ˆæ— æ ‡é¢˜ï¼Œä½¿ç”¨å…±äº«Yè½´èŒƒå›´ï¼‰
        self._plot_subplot(
            axes[0], 
            dataset_local_map, 
            datasets, 
            noise_list,
            'Local Accuracy (%)',
            title=None,
            show_legend=False,
            y_lim=shared_y_lim
        )
        
        # ç»˜åˆ¶ç¬¬äºŒä¸ªå­å›¾ï¼šNeighbor Accuracyï¼ˆæ— æ ‡é¢˜ï¼Œä½¿ç”¨å…±äº«Yè½´èŒƒå›´ï¼‰
        self._plot_subplot(
            axes[1], 
            dataset_neighbor_map, 
            datasets, 
            noise_list,
            'Neighbor Accuracy (%)',
            title=None,
            show_legend=False,
            y_lim=shared_y_lim
        )
        
        # ç»˜åˆ¶ç¬¬ä¸‰ä¸ªå­å›¾ï¼šMIA Success Rateï¼ˆæ— æ ‡é¢˜ï¼ŒåŒ…å«å›¾ä¾‹ï¼‰
        self._plot_subplot(
            axes[2], 
            dataset_mia_map, 
            datasets, 
            noise_list,
            'MIA Success Rate (%)',
            title=None,
            show_legend=True,
            y_lim=mia_y_lim
        )
        
        # è°ƒæ•´å¸ƒå±€ï¼Œä¸ºå³ä¾§å›¾ä¾‹ç•™å‡ºç©ºé—´
        plt.tight_layout(rect=[0, 0, 0.97, 1])
        
        # ä¿å­˜å›¾ç‰‡
        self.fig_dir.mkdir(parents=True, exist_ok=True)
        output_path = self.fig_dir / 'mia_analysis_combined.pdf'
        plt.savefig(output_path, bbox_inches='tight', dpi=300)
        print(f"âœ… MIAç»¼åˆåˆ†æå›¾å·²ä¿å­˜: {output_path}")
        plt.close()


# ========== ä¸»å‡½æ•° ==========

def main():
    parser = argparse.ArgumentParser(description="SepFPL å®éªŒç»“æœå¯è§†åŒ–å·¥å…·")
    
    parser.add_argument("--output-dir", type=Path, default=DEFAULT_OUTPUT_DIR, help="æ•°æ®ç›®å½•")
    parser.add_argument("--tail-epochs", type=int, default=DEFAULT_TAIL_EPOCHS, help="ç»Ÿè®¡è½®æ¬¡")
    parser.add_argument("--fig-dir", type=Path, default=DEFAULT_FIG_DIR, help="å›¾ç‰‡ä¿å­˜ç›®å½•")
    
    parser.add_argument("-a", "--all", action="store_true", help="ç»˜åˆ¶æ‰€æœ‰å›¾ç‰‡")
    parser.add_argument("--ablation", action="store_true", help="ç»˜åˆ¶æ¶ˆèå®éªŒåˆ†ç»„æŸ±çŠ¶å›¾")
    parser.add_argument("--sensitivity", action="store_true", help="ç»˜åˆ¶å‚æ•°æ•æ„Ÿæ€§åˆ†ææŠ˜çº¿å›¾")
    parser.add_argument("--mia-analysis", action="store_true", help="ç»˜åˆ¶MIAç»¼åˆåˆ†æå›¾ï¼ˆåŒ…å«3ä¸ªå­å›¾ï¼šLocal Accuracy, Neighbor Accuracy, MIA Attack Success Rateï¼‰")
    
    args = parser.parse_args()
    
    # å¦‚æœè®¾ç½®äº† -a/--allï¼Œåˆ™å¯ç”¨æ‰€æœ‰ç»˜å›¾é€‰é¡¹
    if args.all:
        args.ablation = True
        args.sensitivity = True
        args.mia_analysis = True
    
    if not (args.ablation or args.sensitivity or args.mia_analysis):
        print("âš ï¸  æœªæŒ‡å®šè¦ç»˜åˆ¶çš„å›¾è¡¨ï¼Œä½¿ç”¨ --ablation ç»˜åˆ¶æ¶ˆèå®éªŒå›¾ï¼Œæˆ–ä½¿ç”¨ --sensitivity ç»˜åˆ¶æ•æ„Ÿæ€§åˆ†æå›¾ï¼Œæˆ–ä½¿ç”¨ --mia-analysis ç»˜åˆ¶MIAç»¼åˆåˆ†æå›¾ï¼Œæˆ–ä½¿ç”¨ -a/--all ç»˜åˆ¶æ‰€æœ‰å›¾ç‰‡")
        args.mia_analysis = True
    
    if args.ablation:
        print("\nğŸ“Š æ­£åœ¨ç»˜åˆ¶æ¶ˆèå®éªŒåˆ†ç»„æŸ±çŠ¶å›¾...")
        plot_ablation_study()
    
    if args.sensitivity:
        print("\nğŸ“Š æ­£åœ¨ç»˜åˆ¶å‚æ•°æ•æ„Ÿæ€§åˆ†ææŠ˜çº¿å›¾...")
        SensitivityAnalysisPlotter.plot()
    
    if args.mia_analysis:
        print("\nğŸ“Š æ­£åœ¨ç»˜åˆ¶MIAç»¼åˆåˆ†æå›¾...")
        plotter = MiaAnalysisPlotter(args.output_dir, args.tail_epochs, args.fig_dir)
        plotter.plot()
    
    if args.ablation or args.sensitivity or args.mia_analysis:
        print(f"\nâœ… æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åˆ°: {args.fig_dir}")


if __name__ == "__main__":
    main()

